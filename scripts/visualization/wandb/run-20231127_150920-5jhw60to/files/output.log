11/27/2023 15:09:24 - INFO - pixel.data.rendering.rendering_utils - loading text renderer configuration file https://huggingface.co/Team-PIXEL/pixel-base/resolve/main/text_renderer_config.json from cache at /home/stefania/.cache/huggingface/transformers/892d6a02d7c441000de399de59ed70d943a81f7b0f536523b4af1111677a8508.e332b34c9c05756dd4aa51d8fa33461dbd79604752296d185f03f8004db30700
11/27/2023 15:09:25 - INFO - pixel.data.rendering.rendering_utils - loading font file https://huggingface.co/Team-PIXEL/pixel-base/resolve/main/GoNotoCurrent.ttf from cache at /home/stefania/.cache/huggingface/transformers/49e6dc219d1a1a1c9236acaf05a48b542002016a6dc877ee72baab085a84257b.3f28e7f4b38e1efe1b6da4a3732404c19d4c6a614ff32dce90a251e293d4ce58
11/27/2023 15:09:25 - INFO - pixel.data.rendering.pygame_renderer - Loading font from /home/stefania/.cache/huggingface/transformers/49e6dc219d1a1a1c9236acaf05a48b542002016a6dc877ee72baab085a84257b.3f28e7f4b38e1efe1b6da4a3732404c19d4c6a614ff32dce90a251e293d4ce58
11/27/2023 15:09:25 - INFO - pixel.data.rendering.rendering_utils - Text renderer PyGameTextRenderer {
  "background_color": "white",
  "dpi": 120,
  "font_color": "black",
  "font_file": "49e6dc219d1a1a1c9236acaf05a48b542002016a6dc877ee72baab085a84257b.3f28e7f4b38e1efe1b6da4a3732404c19d4c6a614ff32dce90a251e293d4ce58",
  "font_size": 8,
  "max_seq_length": 256,
  "pad_size": 3,
  "pixels_per_patch": 16,
  "text_renderer_type": "PyGameTextRenderer"
}
11/27/2023 15:09:29 - INFO - pixel.utils.modeling - Truncating position embeddings to 256
Some weights of the model checkpoint at Team-PIXEL/pixel-base were not used when initializing PIXELModelWithMC: ['decoder.decoder_layers.7.attention.attention.query.weight', 'decoder.decoder_layers.0.attention.attention.query.bias', 'decoder.decoder_layers.1.intermediate.dense.weight', 'decoder.decoder_layers.6.layernorm_after.bias', 'decoder.decoder_layers.1.output.dense.weight', 'decoder.decoder_layers.6.layernorm_after.weight', 'decoder.decoder_layers.0.attention.attention.key.bias', 'decoder.decoder_layers.7.intermediate.dense.weight', 'decoder.decoder_layers.1.attention.attention.key.bias', 'decoder.decoder_layers.5.output.dense.weight', 'decoder.decoder_layers.0.intermediate.dense.bias', 'decoder.decoder_layers.0.attention.attention.key.weight', 'decoder.decoder_layers.1.attention.output.dense.bias', 'decoder.decoder_layers.6.intermediate.dense.weight', 'decoder.decoder_layers.6.attention.attention.value.weight', 'decoder.decoder_layers.0.output.dense.bias', 'decoder.decoder_layers.5.attention.attention.value.bias', 'decoder.decoder_layers.2.attention.attention.key.weight', 'decoder.decoder_layers.2.layernorm_after.weight', 'decoder.decoder_layers.6.attention.attention.key.bias', 'decoder.decoder_layers.0.attention.attention.value.bias', 'decoder.decoder_layers.3.output.dense.weight', 'decoder.decoder_layers.6.attention.attention.key.weight', 'decoder.decoder_pred.weight', 'decoder.decoder_layers.0.layernorm_after.weight', 'decoder.decoder_layers.3.layernorm_before.weight', 'decoder.mask_token', 'decoder.decoder_layers.1.attention.attention.value.weight', 'decoder.decoder_layers.0.intermediate.dense.weight', 'decoder.decoder_layers.2.intermediate.dense.weight', 'decoder.decoder_layers.5.layernorm_before.bias', 'decoder.decoder_layers.4.output.dense.bias', 'decoder.decoder_layers.4.attention.attention.query.bias', 'decoder.decoder_layers.1.attention.attention.query.weight', 'decoder.decoder_layers.3.layernorm_after.weight', 'decoder.decoder_layers.6.output.dense.bias', 'decoder.decoder_layers.4.attention.attention.key.bias', 'decoder.decoder_layers.1.layernorm_after.bias', 'decoder.decoder_layers.6.layernorm_before.bias', 'decoder.decoder_layers.6.attention.attention.query.weight', 'decoder.decoder_layers.0.layernorm_after.bias', 'decoder.decoder_norm.bias', 'decoder.decoder_layers.5.output.dense.bias', 'decoder.decoder_layers.7.attention.output.dense.bias', 'decoder.decoder_layers.1.output.dense.bias', 'decoder.decoder_layers.4.attention.attention.key.weight', 'decoder.decoder_layers.4.attention.attention.value.weight', 'decoder.decoder_layers.4.attention.attention.value.bias', 'decoder.decoder_layers.3.attention.attention.key.weight', 'decoder.decoder_layers.5.attention.output.dense.bias', 'decoder.decoder_layers.7.intermediate.dense.bias', 'decoder.decoder_layers.6.attention.output.dense.weight', 'decoder.decoder_layers.7.output.dense.weight', 'decoder.decoder_pred.bias', 'decoder.decoder_layers.6.attention.attention.value.bias', 'decoder.decoder_pos_embed', 'decoder.decoder_embed.bias', 'decoder.decoder_layers.2.output.dense.weight', 'decoder.decoder_layers.3.layernorm_before.bias', 'decoder.decoder_layers.7.attention.attention.query.bias', 'decoder.decoder_layers.1.layernorm_after.weight', 'decoder.decoder_layers.4.layernorm_after.bias', 'decoder.decoder_layers.5.layernorm_before.weight', 'decoder.decoder_layers.3.layernorm_after.bias', 'decoder.decoder_layers.2.intermediate.dense.bias', 'decoder.decoder_layers.1.layernorm_before.weight', 'decoder.decoder_layers.3.output.dense.bias', 'decoder.decoder_layers.1.attention.attention.key.weight', 'decoder.decoder_layers.2.output.dense.bias', 'decoder.decoder_layers.4.layernorm_before.bias', 'decoder.decoder_layers.2.layernorm_after.bias', 'decoder.decoder_layers.7.attention.attention.key.bias', 'decoder.decoder_layers.5.intermediate.dense.weight', 'decoder.decoder_layers.7.layernorm_before.weight', 'decoder.decoder_layers.6.layernorm_before.weight', 'decoder.decoder_layers.7.layernorm_before.bias', 'decoder.decoder_layers.7.layernorm_after.bias', 'decoder.decoder_layers.2.attention.attention.value.weight', 'decoder.decoder_layers.1.attention.output.dense.weight', 'decoder.decoder_layers.2.attention.output.dense.weight', 'decoder.decoder_layers.6.intermediate.dense.bias', 'decoder.decoder_layers.0.attention.attention.value.weight', 'decoder.decoder_layers.4.intermediate.dense.bias', 'decoder.decoder_layers.1.layernorm_before.bias', 'decoder.decoder_norm.weight', 'decoder.decoder_layers.7.attention.attention.value.bias', 'decoder.decoder_layers.1.attention.attention.query.bias', 'decoder.decoder_layers.3.attention.output.dense.weight', 'decoder.decoder_layers.0.attention.output.dense.bias', 'decoder.decoder_layers.7.output.dense.bias', 'decoder.decoder_layers.3.attention.attention.value.weight', 'decoder.decoder_layers.1.intermediate.dense.bias', 'decoder.decoder_layers.3.attention.attention.query.bias', 'decoder.decoder_layers.4.intermediate.dense.weight', 'decoder.decoder_layers.4.attention.output.dense.weight', 'decoder.decoder_layers.2.attention.attention.value.bias', 'decoder.decoder_layers.2.attention.attention.query.weight', 'decoder.decoder_layers.5.attention.output.dense.weight', 'decoder.decoder_layers.0.attention.attention.query.weight', 'decoder.decoder_layers.7.attention.output.dense.weight', 'decoder.decoder_layers.2.attention.attention.key.bias', 'decoder.decoder_layers.5.attention.attention.query.weight', 'decoder.decoder_layers.2.attention.output.dense.bias', 'decoder.decoder_layers.0.layernorm_before.bias', 'decoder.decoder_layers.5.attention.attention.key.weight', 'decoder.decoder_layers.3.intermediate.dense.weight', 'decoder.decoder_layers.7.attention.attention.key.weight', 'decoder.decoder_layers.5.layernorm_after.bias', 'decoder.decoder_layers.0.output.dense.weight', 'decoder.decoder_layers.5.attention.attention.value.weight', 'decoder.decoder_layers.4.output.dense.weight', 'decoder.decoder_layers.6.attention.attention.query.bias', 'decoder.decoder_layers.3.attention.attention.query.weight', 'decoder.decoder_layers.3.intermediate.dense.bias', 'decoder.decoder_layers.4.attention.attention.query.weight', 'decoder.decoder_layers.4.layernorm_after.weight', 'decoder.decoder_layers.5.attention.attention.query.bias', 'decoder.decoder_embed.weight', 'decoder.decoder_layers.3.attention.output.dense.bias', 'decoder.decoder_layers.6.attention.output.dense.bias', 'decoder.decoder_layers.3.attention.attention.key.bias', 'decoder.decoder_layers.2.attention.attention.query.bias', 'decoder.decoder_layers.0.layernorm_before.weight', 'decoder.decoder_layers.4.layernorm_before.weight', 'decoder.decoder_layers.7.attention.attention.value.weight', 'decoder.decoder_layers.7.layernorm_after.weight', 'decoder.decoder_layers.6.output.dense.weight', 'decoder.decoder_layers.1.attention.attention.value.bias', 'decoder.decoder_layers.5.intermediate.dense.bias', 'decoder.decoder_layers.3.attention.attention.value.bias', 'decoder.decoder_layers.2.layernorm_before.weight', 'decoder.decoder_layers.2.layernorm_before.bias', 'decoder.decoder_layers.4.attention.output.dense.bias', 'decoder.decoder_layers.5.layernorm_after.weight', 'decoder.decoder_layers.0.attention.output.dense.weight', 'decoder.decoder_layers.5.attention.attention.key.bias']
- This IS expected if you are initializing PIXELModelWithMC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing PIXELModelWithMC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Traceback (most recent call last):
  File "/media/stefania/A650A6F450A6C9FF/Work/RUG/Master/MA Thesis/pixel-semantic/scripts/visualization/visualize_pixel_uncertainty.py", line 206, in <module>
    main(parsed_args)
  File "/media/stefania/A650A6F450A6C9FF/Work/RUG/Master/MA Thesis/pixel-semantic/scripts/visualization/visualize_pixel_uncertainty.py", line 93, in main
    resize_model_embeddings(model, text_renderer.max_seq_length)
  File "/media/stefania/A650A6F450A6C9FF/Work/RUG/Master/MA Thesis/pixel-semantic/src/pixel/utils/modeling.py", line 42, in resize_model_embeddings
    old_pos_embeds = model.vit.embeddings.position_embeddings[:, : max_seq_length + 1, :]
  File "/home/stefania/anaconda3/envs/pixel-env/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1695, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{name}'")
AttributeError: 'PIXELModelWithMC' object has no attribute 'vit'