{"columns": ["return_dict", "output_hidden_states", "output_attentions", "torchscript", "torch_dtype", "use_bfloat16", "pruned_heads", "tie_word_embeddings", "is_encoder_decoder", "is_decoder", "cross_attention_hidden_size", "add_cross_attention", "tie_encoder_decoder", "max_length", "min_length", "do_sample", "early_stopping", "num_beams", "num_beam_groups", "diversity_penalty", "temperature", "top_k", "top_p", "typical_p", "repetition_penalty", "length_penalty", "no_repeat_ngram_size", "encoder_no_repeat_ngram_size", "bad_words_ids", "num_return_sequences", "chunk_size_feed_forward", "output_scores", "return_dict_in_generate", "forced_bos_token_id", "forced_eos_token_id", "remove_invalid_values", "architectures", "finetuning_task", "id2label", "label2id", "tokenizer_class", "prefix", "bos_token_id", "pad_token_id", "eos_token_id", "sep_token_id", "decoder_start_token_id", "task_specific_params", "problem_type", "_name_or_path", "transformers_version", "model_type", "hidden_size", "num_hidden_layers", "num_attention_heads", "intermediate_size", "hidden_act", "hidden_dropout_prob", "attention_probs_dropout_prob", "initializer_range", "layer_norm_eps", "image_size", "patch_size", "num_channels", "qkv_bias", "decoder_num_attention_heads", "decoder_hidden_size", "decoder_num_hidden_layers", "decoder_intermediate_size", "mask_ratio", "norm_pix_loss"], "data": [[true, false, false, false, "float32", false, {}, true, false, false, null, false, false, 20, 0, false, false, 1, 1, 0.0, 1.0, 50, 1.0, 1.0, 1.0, 1.0, 0, 0, null, 1, 0, false, false, null, null, false, ["PIXELForPreTraining"], null, {"0": "LABEL_0", "1": "LABEL_1"}, {"LABEL_0": 0, "LABEL_1": 1}, null, null, null, null, null, null, null, null, null, "Team-PIXEL/pixel-base", "4.17.0", "pixel", 768, 12, 12, 3072, "gelu", 0.1, 0.1, 0.02, 1e-12, [16, 8464], 16, 3, true, 16, 512, 8, 2048, 0.25, true]]}