The following modules were not unloaded:
  (Use "module --force purge" to unload all):

  1) 2023.01   2) StdEnv
wandb: Currently logged in as: stefania_radu. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.3 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.12
wandb: Run data is saved locally in /home2/s3919609/pixel-semantic/wandb/run-20240304_112126-y6qrxvnq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sleek-yogurt-202
wandb: ‚≠êÔ∏è View project at https://wandb.ai/stefania_radu/pixel-semantic-scripts_visualization
wandb: üöÄ View run at https://wandb.ai/stefania_radu/pixel-semantic-scripts_visualization/runs/y6qrxvnq
03/04/2024 11:21:31 - INFO - pixel.data.rendering.rendering_utils - loading text renderer configuration file https://huggingface.co/Team-PIXEL/pixel-base/resolve/main/text_renderer_config.json from cache at /home2/s3919609/.cache/huggingface/transformers/892d6a02d7c441000de399de59ed70d943a81f7b0f536523b4af1111677a8508.e332b34c9c05756dd4aa51d8fa33461dbd79604752296d185f03f8004db30700
03/04/2024 11:21:31 - INFO - pixel.data.rendering.rendering_utils - loading font file https://huggingface.co/Team-PIXEL/pixel-base/resolve/main/GoNotoCurrent.ttf from cache at /home2/s3919609/.cache/huggingface/transformers/49e6dc219d1a1a1c9236acaf05a48b542002016a6dc877ee72baab085a84257b.3f28e7f4b38e1efe1b6da4a3732404c19d4c6a614ff32dce90a251e293d4ce58
03/04/2024 11:21:31 - INFO - pixel.data.rendering.pygame_renderer - Loading font from /home2/s3919609/.cache/huggingface/transformers/49e6dc219d1a1a1c9236acaf05a48b542002016a6dc877ee72baab085a84257b.3f28e7f4b38e1efe1b6da4a3732404c19d4c6a614ff32dce90a251e293d4ce58
03/04/2024 11:21:31 - INFO - pixel.data.rendering.rendering_utils - Text renderer PyGameTextRenderer {
  "background_color": "white",
  "dpi": 120,
  "font_color": "black",
  "font_file": "49e6dc219d1a1a1c9236acaf05a48b542002016a6dc877ee72baab085a84257b.3f28e7f4b38e1efe1b6da4a3732404c19d4c6a614ff32dce90a251e293d4ce58",
  "font_size": 8,
  "max_seq_length": 256,
  "pad_size": 3,
  "pixels_per_patch": 16,
  "text_renderer_type": "PyGameTextRenderer"
}

03/04/2024 11:21:34 - INFO - pixel.utils.modeling - Truncating position embeddings to 256
03/04/2024 11:21:34 - INFO - pixel.utils.modeling - Truncating decoder position embeddings to 256
03/04/2024 11:21:34 - INFO - __main__ - Running PIXEL masked autoencoding with pixel reconstruction
03/04/2024 11:21:34 - INFO - __main__ - Applying span masking with "max_span_length = 6" , "cumulative_span_weights = [0.2, 0.4, 0.6, 0.8, 0.9, 1.0]"  and "spacing = span"
03/04/2024 11:21:34 - INFO - __main__ - Masked count: 133, ratio = 0.5195
03/04/2024 11:21:34 - INFO - __main__ - Monte Carlo samples: 100
03/04/2024 11:21:34 - INFO - __main__ - Training mode: True
all_attention (samples, layers, batch_size, num_heads, sequence_length, sequence_length): torch.Size([100, 12, 12, 26, 26])
all_attention after mean: torch.Size([12, 12, 26, 26])
03/04/2024 11:22:14 - INFO - __main__ - std_predictions shape: torch.Size([3, 256, 256])
mask.shape: torch.Size([3, 256, 256])
attentions.shape: torch.Size([12, 26, 26])
all_heads_attentions.shape: torch.Size([12, 256, 256])
all_heads_attentions_image: torch.Size([12, 256, 256])
mask.shape: torch.Size([3, 256, 256])
attentions.shape: torch.Size([12, 26, 26])
all_heads_attentions.shape: torch.Size([12, 256, 256])
all_heads_attentions_image: torch.Size([12, 256, 256])
mask.shape: torch.Size([3, 256, 256])
attentions.shape: torch.Size([12, 26, 26])
all_heads_attentions.shape: torch.Size([12, 256, 256])
all_heads_attentions_image: torch.Size([12, 256, 256])
mask.shape: torch.Size([3, 256, 256])
attentions.shape: torch.Size([12, 26, 26])
all_heads_attentions.shape: torch.Size([12, 256, 256])
all_heads_attentions_image: torch.Size([12, 256, 256])
mask.shape: torch.Size([3, 256, 256])
attentions.shape: torch.Size([12, 26, 26])
all_heads_attentions.shape: torch.Size([12, 256, 256])
all_heads_attentions_image: torch.Size([12, 256, 256])
mask.shape: torch.Size([3, 256, 256])
attentions.shape: torch.Size([12, 26, 26])
all_heads_attentions.shape: torch.Size([12, 256, 256])
all_heads_attentions_image: torch.Size([12, 256, 256])
mask.shape: torch.Size([3, 256, 256])
attentions.shape: torch.Size([12, 26, 26])
all_heads_attentions.shape: torch.Size([12, 256, 256])
all_heads_attentions_image: torch.Size([12, 256, 256])
mask.shape: torch.Size([3, 256, 256])
attentions.shape: torch.Size([12, 26, 26])
all_heads_attentions.shape: torch.Size([12, 256, 256])
all_heads_attentions_image: torch.Size([12, 256, 256])
mask.shape: torch.Size([3, 256, 256])
attentions.shape: torch.Size([12, 26, 26])
all_heads_attentions.shape: torch.Size([12, 256, 256])
all_heads_attentions_image: torch.Size([12, 256, 256])
mask.shape: torch.Size([3, 256, 256])
attentions.shape: torch.Size([12, 26, 26])
all_heads_attentions.shape: torch.Size([12, 256, 256])
all_heads_attentions_image: torch.Size([12, 256, 256])
mask.shape: torch.Size([3, 256, 256])
attentions.shape: torch.Size([12, 26, 26])
all_heads_attentions.shape: torch.Size([12, 256, 256])
all_heads_attentions_image: torch.Size([12, 256, 256])
mask.shape: torch.Size([3, 256, 256])
attentions.shape: torch.Size([12, 26, 26])
all_heads_attentions.shape: torch.Size([12, 256, 256])
all_heads_attentions_image: torch.Size([12, 256, 256])
all_layers_attentions: torch.Size([12, 12, 256, 256])
attention_grid: torch.Size([3, 3098, 3098])
attention_grid 0 : tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 1., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]])
attention_grid 1 : tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 1., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]])
Are the channels different? False
03/04/2024 11:22:19 - INFO - __main__ - Mean variance for whole image: 0.027
03/04/2024 11:22:19 - INFO - __main__ - Mean std for whole image: 0.121
03/04/2024 11:22:19 - INFO - __main__ - SD image: [[0.10917105 0.10917105 0.10917105 ... 0.10821953 0.10821953 0.10821953]
 [0.10917105 0.10917105 0.10917105 ... 0.10821953 0.10821953 0.10821953]
 [0.10917105 0.10917105 0.10917105 ... 0.10821953 0.10821953 0.10821953]
 ...
 [0.05909356 0.05909356 0.05909356 ... 0.         0.         0.        ]
 [0.05909356 0.05909356 0.05909356 ... 0.         0.         0.        ]
 [0.05909356 0.05909356 0.05909356 ... 0.         0.         0.        ]]
03/04/2024 11:22:19 - INFO - __main__ - Mean std for whole image patch mean: 0.107
03/04/2024 11:22:19 - INFO - __main__ - mean_std shape: (3, 256, 256)
03/04/2024 11:22:19 - INFO - __main__ - std_predictions shape: torch.Size([3, 256, 256])
mean_predictions: tensor([[[ 0.5290,  0.5297,  0.5300,  ...,  0.5480,  0.5482,  0.5485],
         [ 0.5134,  0.5131,  0.5103,  ...,  0.4612,  0.3442,  0.4226],
         [ 0.4806,  0.4797, -0.4267,  ...,  0.2925,  0.2361,  0.3468],
         ...,
         [ 0.5318,  0.5077,  0.4994,  ...,  0.2278,  0.2698,  0.2199],
         [ 0.5275,  0.5116,  0.5003,  ...,  0.2391,  0.2303,  0.2586],
         [ 0.5045,  0.4997,  0.4979,  ...,  0.2447,  0.2664,  0.2515]],

        [[ 0.5290,  0.5297,  0.5300,  ...,  0.5480,  0.5482,  0.5485],
         [ 0.5134,  0.5131,  0.5103,  ...,  0.4612,  0.3442,  0.4226],
         [ 0.4806,  0.4796, -0.4267,  ...,  0.2925,  0.2362,  0.3468],
         ...,
         [ 0.5318,  0.5076,  0.4994,  ...,  0.2278,  0.2698,  0.2199],
         [ 0.5275,  0.5116,  0.5003,  ...,  0.2391,  0.2304,  0.2586],
         [ 0.5045,  0.4997,  0.4979,  ...,  0.2447,  0.2664,  0.2515]],

        [[ 0.5290,  0.5297,  0.5300,  ...,  0.5480,  0.5482,  0.5485],
         [ 0.5134,  0.5131,  0.5103,  ...,  0.4612,  0.3442,  0.4226],
         [ 0.4806,  0.4797, -0.4267,  ...,  0.2925,  0.2361,  0.3468],
         ...,
         [ 0.5318,  0.5077,  0.4994,  ...,  0.2278,  0.2698,  0.2199],
         [ 0.5274,  0.5116,  0.5003,  ...,  0.2391,  0.2304,  0.2586],
         [ 0.5045,  0.4997,  0.4979,  ...,  0.2447,  0.2664,  0.2515]]])
std_predictions_per_patch: tensor([14.7276, 14.7449, 14.7550, 14.7366, 14.7325, 14.7339, 14.7458, 14.7455,
        14.7363, 14.7336, 14.7519, 14.7433, 14.7315, 14.7332, 14.7319, 14.7367,
        14.7121, 14.7202, 14.7195, 14.7173, 14.7151, 14.7000, 14.7115, 14.7210,
        14.7099, 14.7096, 14.7186, 14.7167, 14.7183, 14.7107, 14.7139, 14.7275,
        21.4522, 21.4653, 21.4608, 21.4547, 21.4537, 21.4426, 21.4578, 21.4682,
        21.4544, 21.4507, 21.4584, 21.4571, 21.4532, 21.4498, 21.4553, 21.4682,
        22.1802, 22.1903, 22.1915, 22.1817, 22.1818, 22.1741, 22.1873, 22.2000,
        22.1794, 22.1724, 22.1945, 22.1796, 22.1799, 22.1834, 22.1772, 22.1976,
        19.9590, 19.9660, 19.9618, 19.9564, 19.9574, 19.9497, 19.9628, 19.9760,
        19.9545, 19.9519, 19.9679, 19.9538, 19.9573, 19.9547, 19.9552, 19.9724,
        24.3808, 24.3821, 24.3790, 24.3673, 24.3667, 24.3701, 24.3842, 24.3975,
        24.3779, 24.3707, 24.3943, 24.3774, 24.3787, 24.3812, 24.3812, 24.3962,
        19.9099, 19.9137, 19.9109, 19.9085, 19.9052, 19.9012, 19.9163, 19.9230,
        19.9105, 19.9089, 19.9136, 19.9150, 19.9133, 19.9101, 19.9137, 19.9240,
         9.9859,  9.9885,  9.9886,  9.9862,  9.9848,  9.9816,  9.9865,  9.9920,
         9.9870,  9.9855,  9.9895,  9.9875,  9.9872,  9.9864,  9.9877,  9.9930,
         8.6300,  8.6328,  8.6325,  8.6305,  8.6292,  8.6264,  8.6305,  8.6348,
         8.6309,  8.6293,  8.6317,  8.6310,  8.6309,  8.6299,  8.6312,  8.6352,
        19.5679, 19.5727, 19.5734, 19.5661, 19.5608, 19.5582, 19.5686, 19.5862,
        19.5737, 19.5621, 19.5704, 19.5703, 19.5673, 19.5640, 19.5670, 19.5796,
        16.9694, 16.9805, 16.9788, 16.9705, 16.9721, 16.9642, 16.9721, 16.9863,
        16.9688, 16.9683, 16.9781, 16.9668, 16.9695, 16.9660, 16.9715, 16.9874,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
        25.5661, 25.5723, 25.5666, 25.5587, 25.5667, 25.5641, 25.5686, 25.5881,
        25.5672, 25.5563, 25.5726, 25.5545, 25.5720, 25.5711, 25.5573, 25.5840,
        24.2803, 24.2908, 24.2734, 24.2676, 24.2800, 24.2622, 24.2729, 24.2978,
        24.2748, 24.2694, 24.2823, 24.2718, 24.2831, 24.2720, 24.2739, 24.2989,
        22.5987, 22.6139, 22.6097, 22.6119, 22.6095, 22.5954, 22.6100, 22.6203,
        22.5999, 22.6028, 22.6151, 22.6149, 22.6102, 22.6050, 22.6116, 22.6274,
        15.1250, 15.1324, 15.1306, 15.1282, 15.1262, 15.1186, 15.1266, 15.1342,
        15.1249, 15.1246, 15.1285, 15.1266, 15.1253, 15.1230, 15.1281, 15.1354])
std_reconstruction_per_patch: tensor([14.7276, 14.7449, 14.7550, 14.7366, 14.7325, 14.7339, 14.7458, 14.7455,
        14.7363, 14.7336, 14.7519, 14.7433, 14.7315, 14.7332, 14.7319, 14.7367,
        14.7121, 14.7202, 14.7195, 14.7173, 14.7151, 14.7000, 14.7115, 14.7210,
        14.7099, 14.7096, 14.7186, 14.7167, 14.7183, 14.7107, 14.7139, 14.7275,
        21.4522, 21.4653, 21.4608, 21.4547, 21.4537, 21.4426, 21.4578, 21.4682,
        21.4544, 21.4507, 21.4584, 21.4571, 21.4532, 21.4498, 21.4553, 21.4682,
        22.1802, 22.1903, 22.1915, 22.1817, 22.1818, 22.1741, 22.1873, 22.2000,
        22.1794, 22.1724, 22.1945, 22.1796, 22.1799, 22.1834, 22.1772, 22.1976,
        19.9590, 19.9660, 19.9618, 19.9564, 19.9574, 19.9497, 19.9628, 19.9760,
        19.9545, 19.9519, 19.9679, 19.9538, 19.9573, 19.9547, 19.9552, 19.9724,
        24.3808, 24.3821, 24.3790, 24.3673, 24.3667, 24.3701, 24.3842, 24.3975,
        24.3779, 24.3707, 24.3943, 24.3774, 24.3787, 24.3812, 24.3812, 24.3962,
        19.9099, 19.9137, 19.9109, 19.9085, 19.9052, 19.9012, 19.9163, 19.9230,
        19.9105, 19.9089, 19.9136, 19.9150, 19.9133, 19.9101, 19.9137, 19.9240,
         9.9859,  9.9885,  9.9886,  9.9862,  9.9848,  9.9816,  9.9865,  9.9920,
         9.9870,  9.9855,  9.9895,  9.9875,  9.9872,  9.9864,  9.9877,  9.9930,
         8.6300,  8.6328,  8.6325,  8.6305,  8.6292,  8.6264,  8.6305,  8.6348,
         8.6309,  8.6293,  8.6317,  8.6310,  8.6309,  8.6299,  8.6312,  8.6352,
        19.5679, 19.5727, 19.5734, 19.5661, 19.5608, 19.5582, 19.5686, 19.5862,
        19.5737, 19.5621, 19.5704, 19.5703, 19.5673, 19.5640, 19.5670, 19.5796,
        16.9694, 16.9805, 16.9788, 16.9705, 16.9721, 16.9642, 16.9721, 16.9863,
        16.9688, 16.9683, 16.9781, 16.9668, 16.9695, 16.9660, 16.9715, 16.9874,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,
        25.5661, 25.5723, 25.5666, 25.5587, 25.5667, 25.5641, 25.5686, 25.5881,
        25.5672, 25.5563, 25.5726, 25.5545, 25.5720, 25.5711, 25.5573, 25.5840,
        24.2803, 24.2908, 24.2734, 24.2676, 24.2800, 24.2622, 24.2729, 24.2978,
        24.2748, 24.2694, 24.2823, 24.2718, 24.2831, 24.2720, 24.2739, 24.2989,
        22.5987, 22.6139, 22.6097, 22.6119, 22.6095, 22.5954, 22.6100, 22.6203,
        22.5999, 22.6028, 22.6151, 22.6149, 22.6102, 22.6050, 22.6116, 22.6274,
        15.1250, 15.1324, 15.1306, 15.1282, 15.1262, 15.1186, 15.1266, 15.1342,
        15.1249, 15.1246, 15.1285, 15.1266, 15.1253, 15.1230, 15.1281, 15.1354])
03/04/2024 11:22:23 - INFO - __main__ - torch.Size([3, 256, 256])
03/04/2024 11:22:23 - INFO - __main__ - torch.Size([3, 256, 256])
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                mask_ratio ‚ñÅ
wandb:            mean_std_value ‚ñÅ
wandb: mean_std_value_patch_mean ‚ñÅ
wandb:       mean_variance_value ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                mask_ratio 0.9
wandb:            mean_std_value 0.121
wandb: mean_std_value_patch_mean 0.107
wandb:       mean_variance_value 0.027
wandb: 
wandb: üöÄ View run sleek-yogurt-202 at: https://wandb.ai/stefania_radu/pixel-semantic-scripts_visualization/runs/y6qrxvnq
wandb: Ô∏è‚ö° View job at https://wandb.ai/stefania_radu/pixel-semantic-scripts_visualization/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjExOTExMzkwMw==/version_details/v50
wandb: Synced 6 W&B file(s), 15 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240304_112126-y6qrxvnq/logs

###############################################################################
H√°br√≥k Cluster
Job 7490022 for user s3919609
Finished at: Mon Mar  4 11:22:33 CET 2024

Job details:
============

Job ID              : 7490022
Name                : experiments_pixel_uncertainty_m0.9
User                : s3919609
Partition           : regularshort
Nodes               : node100
Number of Nodes     : 1
Cores               : 1
Number of Tasks     : 1
State               : RUNNING
Submit              : 2024-03-04T11:20:07
Start               : 2024-03-04T11:20:39
End                 : --
Reserved walltime   : 01:00:00
Used walltime       : 00:01:54
Used CPU time       : --
% User (Computation): --
% System (I/O)      : --
Mem reserved        : 10G
Max Mem (Node/step) : 0.00  (Node unknown, N/A)
Full Max Mem usage  : 0.00  (Until last completed step)
Total Disk Read     : 0.00  (Until last completed step)
Total Disk Write    : 0.00  (Until last completed step)

Acknowledgements:
=================

Please see this page for information about acknowledging H√°br√≥k in your publications:

https://wiki.hpc.rug.nl/habrok/introduction/scientific_output

################################################################################
