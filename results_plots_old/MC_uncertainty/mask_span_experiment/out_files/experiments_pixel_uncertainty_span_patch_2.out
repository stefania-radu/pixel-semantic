The following modules were not unloaded:
  (Use "module --force purge" to unload all):

  1) 2023.01   2) StdEnv
wandb: Currently logged in as: stefania_radu. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.3 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.12
wandb: Run data is saved locally in /home2/s3919609/pixel-semantic/wandb/run-20240304_185208-15rsaidi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dry-sunset-218
wandb: ‚≠êÔ∏è View project at https://wandb.ai/stefania_radu/pixel-semantic-scripts_visualization
wandb: üöÄ View run at https://wandb.ai/stefania_radu/pixel-semantic-scripts_visualization/runs/15rsaidi
03/04/2024 18:52:14 - INFO - pixel.data.rendering.rendering_utils - loading text renderer configuration file https://huggingface.co/Team-PIXEL/pixel-base/resolve/main/text_renderer_config.json from cache at /home2/s3919609/.cache/huggingface/transformers/892d6a02d7c441000de399de59ed70d943a81f7b0f536523b4af1111677a8508.e332b34c9c05756dd4aa51d8fa33461dbd79604752296d185f03f8004db30700
03/04/2024 18:52:15 - INFO - pixel.data.rendering.rendering_utils - loading font file https://huggingface.co/Team-PIXEL/pixel-base/resolve/main/GoNotoCurrent.ttf from cache at /home2/s3919609/.cache/huggingface/transformers/49e6dc219d1a1a1c9236acaf05a48b542002016a6dc877ee72baab085a84257b.3f28e7f4b38e1efe1b6da4a3732404c19d4c6a614ff32dce90a251e293d4ce58
03/04/2024 18:52:15 - INFO - pixel.data.rendering.pygame_renderer - Loading font from /home2/s3919609/.cache/huggingface/transformers/49e6dc219d1a1a1c9236acaf05a48b542002016a6dc877ee72baab085a84257b.3f28e7f4b38e1efe1b6da4a3732404c19d4c6a614ff32dce90a251e293d4ce58
03/04/2024 18:52:15 - INFO - pixel.data.rendering.rendering_utils - Text renderer PyGameTextRenderer {
  "background_color": "white",
  "dpi": 120,
  "font_color": "black",
  "font_file": "49e6dc219d1a1a1c9236acaf05a48b542002016a6dc877ee72baab085a84257b.3f28e7f4b38e1efe1b6da4a3732404c19d4c6a614ff32dce90a251e293d4ce58",
  "font_size": 8,
  "max_seq_length": 256,
  "pad_size": 3,
  "pixels_per_patch": 16,
  "text_renderer_type": "PyGameTextRenderer"
}

03/04/2024 18:52:17 - INFO - pixel.utils.modeling - Truncating position embeddings to 256
03/04/2024 18:52:17 - INFO - pixel.utils.modeling - Truncating decoder position embeddings to 256
03/04/2024 18:52:17 - INFO - __main__ - Running PIXEL masked autoencoding with pixel reconstruction
03/04/2024 18:52:17 - INFO - __main__ - Applying span masking with "max_span_length = 2" , "cumulative_span_weights = [0.0, 1.0]"  and "spacing = span"
03/04/2024 18:52:17 - INFO - __main__ - Masked count: 64, ratio = 0.2500
03/04/2024 18:52:17 - INFO - __main__ - Monte Carlo samples: 100
03/04/2024 18:52:17 - INFO - __main__ - Training mode: True
all_attention (samples, layers, batch_size, num_heads, sequence_length, sequence_length): torch.Size([100, 12, 12, 193, 193])
all_attention after mean: torch.Size([12, 12, 193, 193])
03/04/2024 18:53:38 - INFO - __main__ - std_predictions shape: torch.Size([3, 256, 256])
mask.shape: torch.Size([3, 256, 256])
attentions.shape: torch.Size([12, 193, 193])
all_heads_attentions.shape: torch.Size([12, 256, 256])
all_heads_attentions_image: torch.Size([12, 256, 256])
mask.shape: torch.Size([3, 256, 256])
attentions.shape: torch.Size([12, 193, 193])
all_heads_attentions.shape: torch.Size([12, 256, 256])
all_heads_attentions_image: torch.Size([12, 256, 256])
mask.shape: torch.Size([3, 256, 256])
attentions.shape: torch.Size([12, 193, 193])
all_heads_attentions.shape: torch.Size([12, 256, 256])
all_heads_attentions_image: torch.Size([12, 256, 256])
mask.shape: torch.Size([3, 256, 256])
attentions.shape: torch.Size([12, 193, 193])
all_heads_attentions.shape: torch.Size([12, 256, 256])
all_heads_attentions_image: torch.Size([12, 256, 256])
mask.shape: torch.Size([3, 256, 256])
attentions.shape: torch.Size([12, 193, 193])
all_heads_attentions.shape: torch.Size([12, 256, 256])
all_heads_attentions_image: torch.Size([12, 256, 256])
mask.shape: torch.Size([3, 256, 256])
attentions.shape: torch.Size([12, 193, 193])
all_heads_attentions.shape: torch.Size([12, 256, 256])
all_heads_attentions_image: torch.Size([12, 256, 256])
mask.shape: torch.Size([3, 256, 256])
attentions.shape: torch.Size([12, 193, 193])
all_heads_attentions.shape: torch.Size([12, 256, 256])
all_heads_attentions_image: torch.Size([12, 256, 256])
mask.shape: torch.Size([3, 256, 256])
attentions.shape: torch.Size([12, 193, 193])
all_heads_attentions.shape: torch.Size([12, 256, 256])
all_heads_attentions_image: torch.Size([12, 256, 256])
mask.shape: torch.Size([3, 256, 256])
attentions.shape: torch.Size([12, 193, 193])
all_heads_attentions.shape: torch.Size([12, 256, 256])
all_heads_attentions_image: torch.Size([12, 256, 256])
mask.shape: torch.Size([3, 256, 256])
attentions.shape: torch.Size([12, 193, 193])
all_heads_attentions.shape: torch.Size([12, 256, 256])
all_heads_attentions_image: torch.Size([12, 256, 256])
mask.shape: torch.Size([3, 256, 256])
attentions.shape: torch.Size([12, 193, 193])
all_heads_attentions.shape: torch.Size([12, 256, 256])
all_heads_attentions_image: torch.Size([12, 256, 256])
mask.shape: torch.Size([3, 256, 256])
attentions.shape: torch.Size([12, 193, 193])
all_heads_attentions.shape: torch.Size([12, 256, 256])
all_heads_attentions_image: torch.Size([12, 256, 256])
all_layers_attentions: torch.Size([12, 12, 256, 256])
attention_grid: torch.Size([3, 3098, 3098])
attention_grid 0 : tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0240,  ..., 0.0000, 0.0000, 0.0000],
        ...,
        [0.0000, 0.0000, 0.8401,  ..., 0.9448, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])
attention_grid 1 : tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0240,  ..., 0.0000, 0.0000, 0.0000],
        ...,
        [0.0000, 0.0000, 0.8401,  ..., 0.9448, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])
Are the channels different? False
03/04/2024 18:53:44 - INFO - __main__ - Mean variance for whole image: 0.016
03/04/2024 18:53:44 - INFO - __main__ - Mean std for whole image: 0.1
03/04/2024 18:53:44 - INFO - __main__ - SD image: [[0.         0.         0.         ... 0.01955738 0.01955738 0.01955738]
 [0.         0.         0.         ... 0.01955738 0.01955738 0.01955738]
 [0.         0.         0.         ... 0.01955738 0.01955738 0.01955738]
 ...
 [0.         0.         0.         ... 0.         0.         0.        ]
 [0.         0.         0.         ... 0.         0.         0.        ]
 [0.         0.         0.         ... 0.         0.         0.        ]]
03/04/2024 18:53:44 - INFO - __main__ - Mean std for whole image patch mean: 0.011
03/04/2024 18:53:44 - INFO - __main__ - mean_std shape: (3, 256, 256)
03/04/2024 18:53:44 - INFO - __main__ - std_predictions shape: torch.Size([3, 256, 256])
mean_predictions: tensor([[[ 0.5468,  0.5483,  0.5500,  ...,  0.5838,  0.5842,  0.5842],
         [ 0.5632,  0.5581,  0.6006,  ...,  0.5836,  0.5862,  0.5867],
         [ 0.4555,  0.1790, -0.4581,  ...,  0.5857,  0.5814,  0.5863],
         ...,
         [ 0.7068,  0.6227,  0.6591,  ...,  0.6018,  0.6238,  0.6485],
         [ 0.7615,  0.7087,  0.6657,  ...,  0.3159,  0.5225,  0.6462],
         [ 0.6999,  0.8009,  0.7322,  ...,  0.7774,  0.6798,  0.6125]],

        [[ 0.5468,  0.5483,  0.5500,  ...,  0.5838,  0.5842,  0.5842],
         [ 0.5632,  0.5581,  0.6006,  ...,  0.5836,  0.5863,  0.5867],
         [ 0.4555,  0.1790, -0.4581,  ...,  0.5857,  0.5815,  0.5862],
         ...,
         [ 0.7068,  0.6226,  0.6591,  ...,  0.6018,  0.6238,  0.6485],
         [ 0.7615,  0.7087,  0.6657,  ...,  0.3159,  0.5225,  0.6462],
         [ 0.7000,  0.8009,  0.7322,  ...,  0.7774,  0.6798,  0.6125]],

        [[ 0.5468,  0.5483,  0.5500,  ...,  0.5838,  0.5842,  0.5842],
         [ 0.5632,  0.5581,  0.6006,  ...,  0.5837,  0.5863,  0.5867],
         [ 0.4555,  0.1790, -0.4581,  ...,  0.5858,  0.5814,  0.5862],
         ...,
         [ 0.7068,  0.6226,  0.6592,  ...,  0.6018,  0.6238,  0.6485],
         [ 0.7615,  0.7087,  0.6657,  ...,  0.3159,  0.5225,  0.6462],
         [ 0.6999,  0.8009,  0.7322,  ...,  0.7774,  0.6798,  0.6125]]])
std_predictions_per_patch: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 3.6401, 3.6327,
        3.6356, 3.6452, 3.6375, 3.6331, 3.6319, 3.6311, 3.6392, 3.6349, 3.6384,
        3.6419, 3.6390, 3.6357, 3.6349, 3.6373, 3.0698, 3.0748, 3.0727, 3.0727,
        3.0740, 3.0692, 3.0711, 3.0715, 3.0759, 3.0773, 3.0714, 3.0710, 3.0638,
        3.0637, 3.0697, 3.0735, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 2.9473, 2.9460, 2.9473,
        2.9520, 2.9483, 2.9492, 2.9480, 2.9466, 2.9479, 2.9455, 2.9451, 2.9498,
        2.9434, 2.9463, 2.9458, 2.9501, 3.7168, 3.7115, 3.7070, 3.7098, 3.7079,
        3.7088, 3.7093, 3.7124, 3.7202, 3.7059, 3.7078, 3.7107, 3.7123, 3.7118,
        3.7074, 3.7144, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 7.0625,
        7.0785, 7.1040, 7.1475, 7.1176, 7.1171, 7.1391, 7.1045, 7.0743, 7.1192,
        7.1443, 7.1341, 7.1132, 7.1154, 7.1257, 7.1382, 2.9125, 2.9141, 2.9080,
        2.9123, 2.9140, 2.9102, 2.9118, 2.9149, 2.9159, 2.9140, 2.9129, 2.9145,
        2.9134, 2.9115, 2.9134, 2.9135])
std_reconstruction_per_patch: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 3.6401, 3.6327,
        3.6356, 3.6452, 3.6375, 3.6331, 3.6319, 3.6311, 3.6392, 3.6349, 3.6384,
        3.6419, 3.6390, 3.6357, 3.6349, 3.6373, 3.0698, 3.0748, 3.0727, 3.0727,
        3.0740, 3.0692, 3.0711, 3.0715, 3.0759, 3.0773, 3.0714, 3.0710, 3.0638,
        3.0637, 3.0697, 3.0735, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 2.9473, 2.9460, 2.9473,
        2.9520, 2.9483, 2.9492, 2.9480, 2.9466, 2.9479, 2.9455, 2.9451, 2.9498,
        2.9434, 2.9463, 2.9458, 2.9501, 3.7168, 3.7115, 3.7070, 3.7098, 3.7079,
        3.7088, 3.7093, 3.7124, 3.7202, 3.7059, 3.7078, 3.7107, 3.7123, 3.7118,
        3.7074, 3.7144, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 7.0625,
        7.0785, 7.1040, 7.1475, 7.1176, 7.1171, 7.1391, 7.1045, 7.0743, 7.1192,
        7.1443, 7.1341, 7.1132, 7.1154, 7.1257, 7.1382, 2.9125, 2.9141, 2.9080,
        2.9123, 2.9140, 2.9102, 2.9118, 2.9149, 2.9159, 2.9140, 2.9129, 2.9145,
        2.9134, 2.9115, 2.9134, 2.9135])
03/04/2024 18:53:46 - INFO - __main__ - torch.Size([3, 256, 256])
03/04/2024 18:53:46 - INFO - __main__ - torch.Size([3, 256, 256])
wandb: Waiting for W&B process to finish... (success).
wandb: - 1.544 MB of 1.545 MB uploaded (0.000 MB deduped)wandb: \ 1.545 MB of 1.545 MB uploaded (0.000 MB deduped)wandb: | 1.545 MB of 1.545 MB uploaded (0.000 MB deduped)wandb: / 1.545 MB of 1.545 MB uploaded (0.000 MB deduped)wandb: - 1.545 MB of 1.545 MB uploaded (0.000 MB deduped)wandb: \ 1.545 MB of 1.545 MB uploaded (0.000 MB deduped)wandb: | 1.545 MB of 1.545 MB uploaded (0.000 MB deduped)wandb: / 1.545 MB of 1.545 MB uploaded (0.000 MB deduped)wandb: - 1.545 MB of 1.545 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:                mask_ratio ‚ñÅ
wandb:            mean_std_value ‚ñÅ
wandb: mean_std_value_patch_mean ‚ñÅ
wandb:       mean_variance_value ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                mask_ratio 0.25
wandb:            mean_std_value 0.1
wandb: mean_std_value_patch_mean 0.011
wandb:       mean_variance_value 0.016
wandb: 
wandb: üöÄ View run dry-sunset-218 at: https://wandb.ai/stefania_radu/pixel-semantic-scripts_visualization/runs/15rsaidi
wandb: Ô∏è‚ö° View job at https://wandb.ai/stefania_radu/pixel-semantic-scripts_visualization/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjExOTExMzkwMw==/version_details/v59
wandb: Synced 6 W&B file(s), 15 media file(s), 4 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240304_185208-15rsaidi/logs

###############################################################################
H√°br√≥k Cluster
Job 7509367 for user s3919609
Finished at: Mon Mar  4 18:54:01 CET 2024

Job details:
============

Job ID              : 7509367
Name                : experiments_pixel_uncertainty_span_patch_2
User                : s3919609
Partition           : regularshort
Nodes               : node100
Number of Nodes     : 1
Cores               : 1
Number of Tasks     : 1
State               : COMPLETED
Submit              : 2024-03-04T18:48:33
Start               : 2024-03-04T18:50:59
End                 : 2024-03-04T18:54:01
Reserved walltime   : 01:00:00
Used walltime       : 00:03:02
Used CPU time       : 00:01:42 (efficiency: 56.30%)
% User (Computation): 93.77%
% System (I/O)      :  6.23%
Mem reserved        : 10G
Max Mem (Node/step) : 2.98G (node100, per node)
Full Max Mem usage  : 2.98G
Total Disk Read     : 583.11M
Total Disk Write    : 977.00K

Acknowledgements:
=================

Please see this page for information about acknowledging H√°br√≥k in your publications:

https://wiki.hpc.rug.nl/habrok/introduction/scientific_output

################################################################################
