The following modules were not unloaded:
  (Use "module --force purge" to unload all):

  1) 2023.01   2) StdEnv
11/23/2023 17:58:57 - WARNING - __main__ - Process rank: -1, device: cpu, n_gpu: 0distributed training: False, 16-bits training: False
11/23/2023 17:58:57 - INFO - __main__ - Training/evaluation parameters PIXELTrainingArguments(
_n_gpu=0,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
bf16=False,
bf16_full_eval=False,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=True,
do_train=True,
early_stopping=True,
early_stopping_patience=5,
eval_accumulation_steps=None,
eval_steps=500,
evaluation_strategy=IntervalStrategy.STEPS,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
gradient_accumulation_steps=4,
gradient_checkpointing=False,
greater_is_better=True,
group_by_length=False,
half_precision_backend=apex,
hub_model_id=None,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=3e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=-1,
log_level=-1,
log_level_replica=-1,
log_on_each_node=True,
log_predictions=True,
logging_dir=sst2-pixel-base-mean-pangocairo-256-64-4-3e-5-15000-42/runs/Nov23_17-58-57_a100gpu3,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=100,
logging_strategy=IntervalStrategy.STEPS,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=15000,
metric_for_best_model=eval_accuracy,
mp_parameters=,
no_cuda=False,
num_train_epochs=10.0,
optim=OptimizerNames.ADAMW_HF,
output_dir=sst2-pixel-base-mean-pangocairo-256-64-4-3e-5-15000-42,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=64,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
remove_unused_columns=False,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=sst2-pixel-base-mean-pangocairo-256-64-4-3e-5-15000-42,
save_on_each_node=False,
save_steps=500,
save_strategy=IntervalStrategy.STEPS,
save_total_limit=5,
seed=42,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_legacy_prediction_loop=False,
warmup_ratio=0.0,
warmup_steps=100,
weight_decay=0.0,
xpu_backend=None,
)
https://huggingface.co/datasets/glue/resolve/main/glue.py not found in cache or force_download set to True, downloading to /home2/s3919609/.cache/huggingface/datasets/downloads/03ff78d4e3b8dc3726741609e0bc0e266acd3efa19ccc1c835f7b0fbf8384d86.4ad6b10d4037f376902901afcaf7c8fd58cbf839548cd585189cb35d344e9e0f.py.incomplete
11/23/2023 17:58:58 - INFO - datasets.utils.file_utils - https://huggingface.co/datasets/glue/resolve/main/glue.py not found in cache or force_download set to True, downloading to /home2/s3919609/.cache/huggingface/datasets/downloads/03ff78d4e3b8dc3726741609e0bc0e266acd3efa19ccc1c835f7b0fbf8384d86.4ad6b10d4037f376902901afcaf7c8fd58cbf839548cd585189cb35d344e9e0f.py.incomplete
Downloading builder script:   0%|          | 0.00/28.8k [00:00<?, ?B/s]Downloading builder script: 100%|██████████| 28.8k/28.8k [00:00<00:00, 26.7MB/s]
storing https://huggingface.co/datasets/glue/resolve/main/glue.py in cache at /home2/s3919609/.cache/huggingface/datasets/downloads/03ff78d4e3b8dc3726741609e0bc0e266acd3efa19ccc1c835f7b0fbf8384d86.4ad6b10d4037f376902901afcaf7c8fd58cbf839548cd585189cb35d344e9e0f.py
11/23/2023 17:58:58 - INFO - datasets.utils.file_utils - storing https://huggingface.co/datasets/glue/resolve/main/glue.py in cache at /home2/s3919609/.cache/huggingface/datasets/downloads/03ff78d4e3b8dc3726741609e0bc0e266acd3efa19ccc1c835f7b0fbf8384d86.4ad6b10d4037f376902901afcaf7c8fd58cbf839548cd585189cb35d344e9e0f.py
creating metadata file for /home2/s3919609/.cache/huggingface/datasets/downloads/03ff78d4e3b8dc3726741609e0bc0e266acd3efa19ccc1c835f7b0fbf8384d86.4ad6b10d4037f376902901afcaf7c8fd58cbf839548cd585189cb35d344e9e0f.py
11/23/2023 17:58:58 - INFO - datasets.utils.file_utils - creating metadata file for /home2/s3919609/.cache/huggingface/datasets/downloads/03ff78d4e3b8dc3726741609e0bc0e266acd3efa19ccc1c835f7b0fbf8384d86.4ad6b10d4037f376902901afcaf7c8fd58cbf839548cd585189cb35d344e9e0f.py
https://huggingface.co/datasets/glue/resolve/main/dataset_infos.json not found in cache or force_download set to True, downloading to /home2/s3919609/.cache/huggingface/datasets/downloads/b3da855f86bd64f2a90382d5b68f6a50a890fa9ce3ef4a702eef51fd4e479522.1e6f4f37bbc9505420d0d89bebca59a9b16e9a6cd7ab0db88628ac9a8e40a747.incomplete
11/23/2023 17:58:58 - INFO - datasets.utils.file_utils - https://huggingface.co/datasets/glue/resolve/main/dataset_infos.json not found in cache or force_download set to True, downloading to /home2/s3919609/.cache/huggingface/datasets/downloads/b3da855f86bd64f2a90382d5b68f6a50a890fa9ce3ef4a702eef51fd4e479522.1e6f4f37bbc9505420d0d89bebca59a9b16e9a6cd7ab0db88628ac9a8e40a747.incomplete
Downloading metadata:   0%|          | 0.00/28.7k [00:00<?, ?B/s]Downloading metadata: 100%|██████████| 28.7k/28.7k [00:00<00:00, 25.6MB/s]
storing https://huggingface.co/datasets/glue/resolve/main/dataset_infos.json in cache at /home2/s3919609/.cache/huggingface/datasets/downloads/b3da855f86bd64f2a90382d5b68f6a50a890fa9ce3ef4a702eef51fd4e479522.1e6f4f37bbc9505420d0d89bebca59a9b16e9a6cd7ab0db88628ac9a8e40a747
11/23/2023 17:58:59 - INFO - datasets.utils.file_utils - storing https://huggingface.co/datasets/glue/resolve/main/dataset_infos.json in cache at /home2/s3919609/.cache/huggingface/datasets/downloads/b3da855f86bd64f2a90382d5b68f6a50a890fa9ce3ef4a702eef51fd4e479522.1e6f4f37bbc9505420d0d89bebca59a9b16e9a6cd7ab0db88628ac9a8e40a747
creating metadata file for /home2/s3919609/.cache/huggingface/datasets/downloads/b3da855f86bd64f2a90382d5b68f6a50a890fa9ce3ef4a702eef51fd4e479522.1e6f4f37bbc9505420d0d89bebca59a9b16e9a6cd7ab0db88628ac9a8e40a747
11/23/2023 17:58:59 - INFO - datasets.utils.file_utils - creating metadata file for /home2/s3919609/.cache/huggingface/datasets/downloads/b3da855f86bd64f2a90382d5b68f6a50a890fa9ce3ef4a702eef51fd4e479522.1e6f4f37bbc9505420d0d89bebca59a9b16e9a6cd7ab0db88628ac9a8e40a747
https://huggingface.co/datasets/glue/resolve/main/README.md not found in cache or force_download set to True, downloading to /home2/s3919609/.cache/huggingface/datasets/downloads/55feec413a92e2bb3525cd297350424529de1d8325cd5eb1aca38d722ac9290a.9e0e247217c07bdf24fa19e779072f951dd810c0c78d83acf79c560899877660.incomplete
11/23/2023 17:58:59 - INFO - datasets.utils.file_utils - https://huggingface.co/datasets/glue/resolve/main/README.md not found in cache or force_download set to True, downloading to /home2/s3919609/.cache/huggingface/datasets/downloads/55feec413a92e2bb3525cd297350424529de1d8325cd5eb1aca38d722ac9290a.9e0e247217c07bdf24fa19e779072f951dd810c0c78d83acf79c560899877660.incomplete
Downloading readme:   0%|          | 0.00/27.9k [00:00<?, ?B/s]Downloading readme: 100%|██████████| 27.9k/27.9k [00:00<00:00, 24.0MB/s]
storing https://huggingface.co/datasets/glue/resolve/main/README.md in cache at /home2/s3919609/.cache/huggingface/datasets/downloads/55feec413a92e2bb3525cd297350424529de1d8325cd5eb1aca38d722ac9290a.9e0e247217c07bdf24fa19e779072f951dd810c0c78d83acf79c560899877660
11/23/2023 17:58:59 - INFO - datasets.utils.file_utils - storing https://huggingface.co/datasets/glue/resolve/main/README.md in cache at /home2/s3919609/.cache/huggingface/datasets/downloads/55feec413a92e2bb3525cd297350424529de1d8325cd5eb1aca38d722ac9290a.9e0e247217c07bdf24fa19e779072f951dd810c0c78d83acf79c560899877660
creating metadata file for /home2/s3919609/.cache/huggingface/datasets/downloads/55feec413a92e2bb3525cd297350424529de1d8325cd5eb1aca38d722ac9290a.9e0e247217c07bdf24fa19e779072f951dd810c0c78d83acf79c560899877660
11/23/2023 17:58:59 - INFO - datasets.utils.file_utils - creating metadata file for /home2/s3919609/.cache/huggingface/datasets/downloads/55feec413a92e2bb3525cd297350424529de1d8325cd5eb1aca38d722ac9290a.9e0e247217c07bdf24fa19e779072f951dd810c0c78d83acf79c560899877660
Loading Dataset Infos from /home2/s3919609/.cache/huggingface/modules/datasets_modules/datasets/glue/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad
11/23/2023 17:58:59 - INFO - datasets.info - Loading Dataset Infos from /home2/s3919609/.cache/huggingface/modules/datasets_modules/datasets/glue/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad
Generating dataset glue (/home2/s3919609/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)
11/23/2023 17:59:00 - INFO - datasets.builder - Generating dataset glue (/home2/s3919609/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)
Downloading and preparing dataset glue/sst2 to /home2/s3919609/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad...
11/23/2023 17:59:00 - INFO - datasets.builder - Downloading and preparing dataset glue/sst2 to /home2/s3919609/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad...
Dataset not on Hf google storage. Downloading and preparing it from source
11/23/2023 17:59:00 - INFO - datasets.builder - Dataset not on Hf google storage. Downloading and preparing it from source
https://dl.fbaipublicfiles.com/glue/data/SST-2.zip not found in cache or force_download set to True, downloading to /home2/s3919609/.cache/huggingface/datasets/downloads/fda31747115223e6a71a9b791b0723e7b113a7441b9ebc2eacd14d31e2a855ba.incomplete
11/23/2023 17:59:00 - INFO - datasets.utils.file_utils - https://dl.fbaipublicfiles.com/glue/data/SST-2.zip not found in cache or force_download set to True, downloading to /home2/s3919609/.cache/huggingface/datasets/downloads/fda31747115223e6a71a9b791b0723e7b113a7441b9ebc2eacd14d31e2a855ba.incomplete
Downloading data:   0%|          | 0.00/7.44M [00:00<?, ?B/s]Downloading data:  55%|█████▌    | 4.09M/7.44M [00:00<00:00, 40.9MB/s]Downloading data: 100%|██████████| 7.44M/7.44M [00:00<00:00, 49.7MB/s]
storing https://dl.fbaipublicfiles.com/glue/data/SST-2.zip in cache at /home2/s3919609/.cache/huggingface/datasets/downloads/fda31747115223e6a71a9b791b0723e7b113a7441b9ebc2eacd14d31e2a855ba
11/23/2023 17:59:01 - INFO - datasets.utils.file_utils - storing https://dl.fbaipublicfiles.com/glue/data/SST-2.zip in cache at /home2/s3919609/.cache/huggingface/datasets/downloads/fda31747115223e6a71a9b791b0723e7b113a7441b9ebc2eacd14d31e2a855ba
creating metadata file for /home2/s3919609/.cache/huggingface/datasets/downloads/fda31747115223e6a71a9b791b0723e7b113a7441b9ebc2eacd14d31e2a855ba
11/23/2023 17:59:01 - INFO - datasets.utils.file_utils - creating metadata file for /home2/s3919609/.cache/huggingface/datasets/downloads/fda31747115223e6a71a9b791b0723e7b113a7441b9ebc2eacd14d31e2a855ba
Downloading took 0.0 min
11/23/2023 17:59:01 - INFO - datasets.download.download_manager - Downloading took 0.0 min
Checksum Computation took 0.0 min
11/23/2023 17:59:01 - INFO - datasets.download.download_manager - Checksum Computation took 0.0 min
Generating train split
11/23/2023 17:59:01 - INFO - datasets.builder - Generating train split
Generating train split:   0%|          | 0/67349 [00:00<?, ? examples/s]Generating train split:   1%|▏         | 1000/67349 [00:00<00:31, 2089.68 examples/s]Generating train split:   6%|▋         | 4343/67349 [00:00<00:06, 9294.23 examples/s]Generating train split:  12%|█▏        | 8000/67349 [00:00<00:03, 15969.34 examples/s]Generating train split:  17%|█▋        | 11672/67349 [00:00<00:02, 21366.25 examples/s]Generating train split:  23%|██▎       | 15226/67349 [00:00<00:02, 25202.77 examples/s]Generating train split:  28%|██▊       | 18893/67349 [00:00<00:01, 28401.55 examples/s]Generating train split:  33%|███▎      | 22484/67349 [00:01<00:01, 30538.62 examples/s]Generating train split:  39%|███▊      | 26074/67349 [00:01<00:01, 32086.13 examples/s]Generating train split:  44%|████▍     | 29750/67349 [00:01<00:01, 33451.75 examples/s]Generating train split:  52%|█████▏    | 35107/67349 [00:01<00:00, 34319.20 examples/s]Generating train split:  58%|█████▊    | 38783/67349 [00:01<00:00, 34971.30 examples/s]Generating train split:  66%|██████▌   | 44169/67349 [00:01<00:00, 35308.10 examples/s]Generating train split:  71%|███████   | 47878/67349 [00:01<00:00, 35623.13 examples/s]Generating train split:  79%|███████▉  | 53253/67349 [00:01<00:00, 35692.34 examples/s]Generating train split:  85%|████████▍ | 56930/67349 [00:02<00:00, 35963.48 examples/s]Generating train split:  92%|█████████▏| 62230/67349 [00:02<00:00, 24102.63 examples/s]Generating train split:  98%|█████████▊| 65868/67349 [00:02<00:00, 26353.54 examples/s]Generating train split: 100%|██████████| 67349/67349 [00:02<00:00, 26432.42 examples/s]
Generating validation split
11/23/2023 17:59:04 - INFO - datasets.builder - Generating validation split
Generating validation split:   0%|          | 0/872 [00:00<?, ? examples/s]Generating validation split: 100%|██████████| 872/872 [00:00<00:00, 26632.83 examples/s]
Generating test split
11/23/2023 17:59:04 - INFO - datasets.builder - Generating test split
Generating test split:   0%|          | 0/1821 [00:00<?, ? examples/s]Generating test split: 100%|██████████| 1821/1821 [00:00<00:00, 31412.00 examples/s]
All the splits matched successfully.
11/23/2023 17:59:04 - INFO - datasets.utils.info_utils - All the splits matched successfully.
Dataset glue downloaded and prepared to /home2/s3919609/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad. Subsequent calls will reuse this data.
11/23/2023 17:59:04 - INFO - datasets.builder - Dataset glue downloaded and prepared to /home2/s3919609/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad. Subsequent calls will reuse this data.
[INFO|file_utils.py:2215] 2023-11-23 17:59:04,538 >> https://huggingface.co/Team-PIXEL/pixel-base/resolve/main/config.json not found in cache or force_download set to True, downloading to /home2/s3919609/.cache/huggingface/transformers/tmpjxoo_n_n
Downloading:   0%|          | 0.00/686 [00:00<?, ?B/s]Downloading: 100%|██████████| 686/686 [00:00<00:00, 5.90MB/s]
[INFO|file_utils.py:2219] 2023-11-23 17:59:04,693 >> storing https://huggingface.co/Team-PIXEL/pixel-base/resolve/main/config.json in cache at /home2/s3919609/.cache/huggingface/transformers/59ff3d0d96dd81437a11bdeafa5fad304064b3b0aea12a07ee093116a26dea72.73d98f997dc77ccebbd7d8f1f6b14deb97f467b7ecb1fd28b115bee90138c954
[INFO|file_utils.py:2227] 2023-11-23 17:59:04,695 >> creating metadata file for /home2/s3919609/.cache/huggingface/transformers/59ff3d0d96dd81437a11bdeafa5fad304064b3b0aea12a07ee093116a26dea72.73d98f997dc77ccebbd7d8f1f6b14deb97f467b7ecb1fd28b115bee90138c954
[INFO|configuration_utils.py:648] 2023-11-23 17:59:04,703 >> loading configuration file https://huggingface.co/Team-PIXEL/pixel-base/resolve/main/config.json from cache at /home2/s3919609/.cache/huggingface/transformers/59ff3d0d96dd81437a11bdeafa5fad304064b3b0aea12a07ee093116a26dea72.73d98f997dc77ccebbd7d8f1f6b14deb97f467b7ecb1fd28b115bee90138c954
[INFO|configuration_utils.py:684] 2023-11-23 17:59:04,706 >> Model config PIXELConfig {
  "_name_or_path": "Team-PIXEL/pixel-base",
  "architectures": [
    "PIXELForPreTraining"
  ],
  "attention_probs_dropout_prob": 0.1,
  "decoder_hidden_size": 512,
  "decoder_intermediate_size": 2048,
  "decoder_num_attention_heads": 16,
  "decoder_num_hidden_layers": 8,
  "finetuning_task": "sst2",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "image_size": [
    16,
    8464
  ],
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "mask_ratio": 0.25,
  "model_type": "pixel",
  "norm_pix_loss": true,
  "num_attention_heads": 12,
  "num_channels": 3,
  "num_hidden_layers": 12,
  "patch_size": 16,
  "qkv_bias": true,
  "torch_dtype": "float32",
  "transformers_version": "4.17.0"
}

11/23/2023 17:59:04 - INFO - __main__ - Using dropout with probability 0.1
[INFO|file_utils.py:2215] 2023-11-23 17:59:04,866 >> https://huggingface.co/Team-PIXEL/pixel-base/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /home2/s3919609/.cache/huggingface/transformers/tmplbhc0x08
Downloading:   0%|          | 0.00/429M [00:00<?, ?B/s]Downloading:   0%|          | 50.0k/429M [00:00<26:36, 281kB/s]Downloading:   0%|          | 311k/429M [00:00<07:38, 979kB/s] Downloading:   0%|          | 0.98M/429M [00:00<02:34, 2.90MB/s]Downloading:   1%|          | 2.22M/429M [00:00<01:13, 6.05MB/s]Downloading:   1%|          | 4.17M/429M [00:00<00:42, 10.5MB/s]Downloading:   2%|▏         | 7.98M/429M [00:00<00:22, 19.5MB/s]Downloading:   3%|▎         | 11.3M/429M [00:00<00:20, 21.1MB/s]Downloading:   3%|▎         | 15.0M/429M [00:01<00:16, 25.8MB/s]Downloading:   5%|▍         | 19.4M/429M [00:01<00:13, 31.6MB/s]Downloading:   5%|▌         | 23.0M/429M [00:01<00:12, 33.3MB/s]Downloading:   6%|▋         | 27.1M/429M [00:01<00:11, 36.2MB/s]Downloading:   7%|▋         | 31.6M/429M [00:01<00:10, 39.4MB/s]Downloading:   9%|▊         | 37.2M/429M [00:01<00:09, 45.1MB/s]Downloading:  10%|▉         | 41.6M/429M [00:01<00:10, 37.8MB/s]Downloading:  11%|█         | 47.2M/429M [00:01<00:09, 43.3MB/s]Downloading:  12%|█▏        | 51.6M/429M [00:01<00:09, 43.2MB/s]Downloading:  13%|█▎        | 56.4M/429M [00:01<00:08, 45.4MB/s]Downloading:  14%|█▍        | 60.9M/429M [00:02<00:09, 39.3MB/s]Downloading:  15%|█▌        | 64.9M/429M [00:02<00:09, 39.6MB/s]Downloading:  16%|█▋        | 70.0M/429M [00:02<00:08, 43.3MB/s]Downloading:  17%|█▋        | 74.3M/429M [00:02<00:08, 43.7MB/s]Downloading:  18%|█▊        | 78.8M/429M [00:02<00:08, 44.9MB/s]Downloading:  20%|█▉        | 83.7M/429M [00:02<00:08, 40.5MB/s]Downloading:  20%|██        | 87.8M/429M [00:02<00:08, 41.1MB/s]Downloading:  21%|██▏       | 92.0M/429M [00:02<00:08, 41.9MB/s]Downloading:  22%|██▏       | 96.1M/429M [00:03<00:08, 42.0MB/s]Downloading:  24%|██▎       | 101M/429M [00:03<00:07, 44.6MB/s] Downloading:  25%|██▍       | 105M/429M [00:03<00:07, 45.3MB/s]Downloading:  26%|██▌       | 110M/429M [00:03<00:07, 46.1MB/s]Downloading:  27%|██▋       | 114M/429M [00:03<00:07, 46.2MB/s]Downloading:  28%|██▊       | 119M/429M [00:03<00:08, 39.8MB/s]Downloading:  29%|██▊       | 123M/429M [00:03<00:07, 40.8MB/s]Downloading:  30%|██▉       | 129M/429M [00:03<00:06, 45.5MB/s]Downloading:  31%|███       | 133M/429M [00:03<00:06, 45.0MB/s]Downloading:  32%|███▏      | 138M/429M [00:04<00:07, 40.7MB/s]Downloading:  33%|███▎      | 142M/429M [00:04<00:07, 41.4MB/s]Downloading:  34%|███▍      | 147M/429M [00:04<00:06, 43.3MB/s]Downloading:  35%|███▌      | 151M/429M [00:04<00:06, 43.3MB/s]Downloading:  36%|███▋      | 156M/429M [00:04<00:06, 44.7MB/s]Downloading:  37%|███▋      | 160M/429M [00:04<00:06, 45.2MB/s]Downloading:  38%|███▊      | 165M/429M [00:04<00:06, 45.9MB/s]Downloading:  39%|███▉      | 169M/429M [00:04<00:05, 46.3MB/s]Downloading:  40%|████      | 173M/429M [00:04<00:06, 40.4MB/s]Downloading:  42%|████▏     | 178M/429M [00:04<00:06, 42.0MB/s]Downloading:  42%|████▏     | 182M/429M [00:05<00:06, 42.1MB/s]Downloading:  43%|████▎     | 186M/429M [00:05<00:07, 34.4MB/s]Downloading:  44%|████▍     | 190M/429M [00:05<00:06, 36.1MB/s]Downloading:  45%|████▌     | 194M/429M [00:05<00:06, 37.0MB/s]Downloading:  46%|████▌     | 198M/429M [00:05<00:07, 32.2MB/s]Downloading:  47%|████▋     | 202M/429M [00:05<00:06, 34.9MB/s]Downloading:  48%|████▊     | 205M/429M [00:05<00:06, 36.1MB/s]Downloading:  49%|████▉     | 209M/429M [00:05<00:07, 32.7MB/s]Downloading:  50%|████▉     | 213M/429M [00:06<00:06, 33.7MB/s]Downloading:  51%|█████     | 217M/429M [00:06<00:06, 34.9MB/s]Downloading:  51%|█████▏    | 221M/429M [00:06<00:05, 37.2MB/s]Downloading:  52%|█████▏    | 225M/429M [00:06<00:05, 38.3MB/s]Downloading:  53%|█████▎    | 229M/429M [00:06<00:05, 39.4MB/s]Downloading:  54%|█████▍    | 232M/429M [00:06<00:05, 34.3MB/s]Downloading:  55%|█████▌    | 236M/429M [00:06<00:06, 28.9MB/s]Downloading:  56%|█████▌    | 239M/429M [00:06<00:06, 29.7MB/s]Downloading:  56%|█████▋    | 242M/429M [00:07<00:06, 30.7MB/s]Downloading:  57%|█████▋    | 245M/429M [00:07<00:06, 31.1MB/s]Downloading:  58%|█████▊    | 248M/429M [00:07<00:07, 26.8MB/s]Downloading:  59%|█████▊    | 251M/429M [00:07<00:06, 27.4MB/s]Downloading:  59%|█████▉    | 254M/429M [00:07<00:06, 28.3MB/s]Downloading:  60%|██████    | 257M/429M [00:07<00:06, 26.3MB/s]Downloading:  61%|██████    | 260M/429M [00:07<00:06, 26.8MB/s]Downloading:  61%|██████▏   | 263M/429M [00:07<00:06, 28.2MB/s]Downloading:  62%|██████▏   | 266M/429M [00:07<00:05, 30.1MB/s]Downloading:  63%|██████▎   | 270M/429M [00:08<00:06, 27.2MB/s]Downloading:  64%|██████▎   | 273M/429M [00:08<00:05, 27.8MB/s]Downloading:  64%|██████▍   | 276M/429M [00:08<00:05, 28.5MB/s]Downloading:  65%|██████▌   | 279M/429M [00:08<00:05, 30.6MB/s]Downloading:  66%|██████▌   | 282M/429M [00:08<00:04, 32.0MB/s]Downloading:  67%|██████▋   | 285M/429M [00:08<00:05, 27.6MB/s]Downloading:  67%|██████▋   | 288M/429M [00:08<00:05, 28.0MB/s]Downloading:  68%|██████▊   | 292M/429M [00:08<00:04, 30.0MB/s]Downloading:  69%|██████▉   | 295M/429M [00:08<00:04, 32.1MB/s]Downloading:  70%|██████▉   | 298M/429M [00:09<00:04, 27.7MB/s]Downloading:  70%|███████   | 302M/429M [00:09<00:04, 29.6MB/s]Downloading:  71%|███████   | 305M/429M [00:09<00:04, 30.8MB/s]Downloading:  72%|███████▏  | 308M/429M [00:09<00:03, 32.6MB/s]Downloading:  73%|███████▎  | 312M/429M [00:09<00:04, 28.1MB/s]Downloading:  73%|███████▎  | 315M/429M [00:09<00:04, 29.7MB/s]Downloading:  74%|███████▍  | 318M/429M [00:09<00:03, 30.6MB/s]Downloading:  75%|███████▍  | 321M/429M [00:09<00:03, 31.8MB/s]Downloading:  76%|███████▌  | 325M/429M [00:09<00:03, 28.4MB/s]Downloading:  76%|███████▋  | 327M/429M [00:10<00:03, 29.0MB/s]Downloading:  77%|███████▋  | 331M/429M [00:10<00:03, 30.0MB/s]Downloading:  78%|███████▊  | 334M/429M [00:10<00:03, 31.1MB/s]Downloading:  79%|███████▊  | 337M/429M [00:10<00:02, 32.8MB/s]Downloading:  79%|███████▉  | 341M/429M [00:10<00:03, 29.4MB/s]Downloading:  80%|████████  | 344M/429M [00:10<00:03, 29.6MB/s]Downloading:  81%|████████  | 347M/429M [00:10<00:02, 30.8MB/s]Downloading:  82%|████████▏ | 350M/429M [00:10<00:02, 31.4MB/s]Downloading:  82%|████████▏ | 354M/429M [00:10<00:02, 32.9MB/s]Downloading:  83%|████████▎ | 357M/429M [00:11<00:02, 30.5MB/s]Downloading:  84%|████████▍ | 360M/429M [00:11<00:02, 29.8MB/s]Downloading:  85%|████████▍ | 364M/429M [00:11<00:02, 31.7MB/s]Downloading:  86%|████████▌ | 367M/429M [00:11<00:02, 31.6MB/s]Downloading:  86%|████████▋ | 370M/429M [00:11<00:01, 33.0MB/s]Downloading:  87%|████████▋ | 374M/429M [00:11<00:01, 31.6MB/s]Downloading:  88%|████████▊ | 377M/429M [00:11<00:01, 30.0MB/s]Downloading:  89%|████████▊ | 380M/429M [00:11<00:01, 32.0MB/s]Downloading:  89%|████████▉ | 383M/429M [00:11<00:01, 31.4MB/s]Downloading:  90%|█████████ | 387M/429M [00:12<00:01, 33.2MB/s]Downloading:  91%|█████████ | 390M/429M [00:12<00:01, 31.4MB/s]Downloading:  92%|█████████▏| 393M/429M [00:12<00:01, 30.4MB/s]Downloading:  93%|█████████▎| 397M/429M [00:12<00:01, 31.8MB/s]Downloading:  93%|█████████▎| 400M/429M [00:12<00:00, 31.1MB/s]Downloading:  94%|█████████▍| 403M/429M [00:12<00:00, 33.3MB/s]Downloading:  95%|█████████▍| 407M/429M [00:12<00:00, 32.5MB/s]Downloading:  96%|█████████▌| 410M/429M [00:12<00:00, 30.7MB/s]Downloading:  96%|█████████▋| 413M/429M [00:12<00:00, 31.4MB/s]Downloading:  97%|█████████▋| 416M/429M [00:13<00:00, 31.6MB/s]Downloading:  98%|█████████▊| 419M/429M [00:13<00:00, 31.3MB/s]Downloading:  99%|█████████▊| 423M/429M [00:13<00:00, 33.4MB/s]Downloading:  99%|█████████▉| 426M/429M [00:13<00:00, 33.6MB/s]Downloading: 100%|██████████| 429M/429M [00:13<00:00, 33.5MB/s]
[INFO|file_utils.py:2219] 2023-11-23 17:59:19,964 >> storing https://huggingface.co/Team-PIXEL/pixel-base/resolve/main/pytorch_model.bin in cache at /home2/s3919609/.cache/huggingface/transformers/23b2e1587613b3d2d70a201b2326daa71157ae7590931531a595a6e714d79082.ac3a74956154d5b2812a6f968fa8dbd30b54b3f394c4c468d029f1ff79367617
[INFO|file_utils.py:2227] 2023-11-23 17:59:19,966 >> creating metadata file for /home2/s3919609/.cache/huggingface/transformers/23b2e1587613b3d2d70a201b2326daa71157ae7590931531a595a6e714d79082.ac3a74956154d5b2812a6f968fa8dbd30b54b3f394c4c468d029f1ff79367617
[INFO|modeling_utils.py:1431] 2023-11-23 17:59:19,974 >> loading weights file https://huggingface.co/Team-PIXEL/pixel-base/resolve/main/pytorch_model.bin from cache at /home2/s3919609/.cache/huggingface/transformers/23b2e1587613b3d2d70a201b2326daa71157ae7590931531a595a6e714d79082.ac3a74956154d5b2812a6f968fa8dbd30b54b3f394c4c468d029f1ff79367617
[WARNING|modeling_utils.py:1693] 2023-11-23 17:59:23,092 >> Some weights of the model checkpoint at Team-PIXEL/pixel-base were not used when initializing PIXELForSequenceClassification: ['decoder.decoder_layers.0.attention.output.dense.weight', 'decoder.decoder_layers.6.layernorm_before.bias', 'decoder.decoder_layers.4.layernorm_after.weight', 'decoder.decoder_layers.3.attention.attention.key.bias', 'decoder.mask_token', 'decoder.decoder_layers.6.attention.attention.query.bias', 'decoder.decoder_layers.1.attention.output.dense.bias', 'decoder.decoder_layers.0.attention.attention.value.weight', 'decoder.decoder_layers.0.layernorm_before.weight', 'decoder.decoder_layers.3.layernorm_before.weight', 'decoder.decoder_layers.7.intermediate.dense.bias', 'decoder.decoder_layers.5.attention.attention.key.bias', 'decoder.decoder_layers.2.attention.output.dense.bias', 'decoder.decoder_layers.2.attention.attention.query.weight', 'decoder.decoder_layers.6.layernorm_after.weight', 'decoder.decoder_layers.3.output.dense.weight', 'decoder.decoder_layers.6.attention.attention.value.bias', 'decoder.decoder_layers.0.output.dense.weight', 'decoder.decoder_layers.1.attention.attention.query.weight', 'decoder.decoder_layers.2.layernorm_after.weight', 'decoder.decoder_layers.6.attention.attention.value.weight', 'decoder.decoder_layers.0.intermediate.dense.bias', 'decoder.decoder_layers.1.intermediate.dense.weight', 'decoder.decoder_layers.2.output.dense.weight', 'decoder.decoder_layers.4.layernorm_before.weight', 'decoder.decoder_layers.6.layernorm_before.weight', 'decoder.decoder_layers.5.layernorm_after.bias', 'decoder.decoder_layers.2.intermediate.dense.weight', 'decoder.decoder_layers.7.attention.attention.value.weight', 'decoder.decoder_layers.6.attention.output.dense.weight', 'decoder.decoder_layers.5.attention.output.dense.bias', 'decoder.decoder_layers.1.attention.attention.key.weight', 'decoder.decoder_layers.2.attention.attention.value.bias', 'decoder.decoder_layers.3.intermediate.dense.bias', 'decoder.decoder_pred.bias', 'decoder.decoder_layers.0.attention.output.dense.bias', 'decoder.decoder_layers.2.attention.attention.key.bias', 'decoder.decoder_layers.5.intermediate.dense.bias', 'decoder.decoder_layers.2.attention.output.dense.weight', 'decoder.decoder_layers.0.layernorm_after.weight', 'decoder.decoder_layers.3.layernorm_after.weight', 'decoder.decoder_layers.2.layernorm_after.bias', 'decoder.decoder_layers.3.attention.attention.key.weight', 'decoder.decoder_layers.0.attention.attention.value.bias', 'decoder.decoder_layers.7.layernorm_after.weight', 'decoder.decoder_layers.1.layernorm_after.weight', 'decoder.decoder_pos_embed', 'decoder.decoder_embed.weight', 'decoder.decoder_layers.7.intermediate.dense.weight', 'decoder.decoder_layers.0.layernorm_after.bias', 'decoder.decoder_layers.3.attention.attention.value.bias', 'decoder.decoder_layers.6.attention.attention.key.weight', 'decoder.decoder_pred.weight', 'decoder.decoder_layers.5.output.dense.bias', 'decoder.decoder_layers.1.attention.attention.value.weight', 'decoder.decoder_layers.7.output.dense.bias', 'decoder.decoder_layers.4.intermediate.dense.bias', 'decoder.decoder_layers.4.output.dense.bias', 'decoder.decoder_layers.3.intermediate.dense.weight', 'decoder.decoder_layers.4.attention.attention.query.weight', 'decoder.decoder_layers.1.output.dense.weight', 'decoder.decoder_layers.1.attention.attention.value.bias', 'decoder.decoder_layers.5.layernorm_before.weight', 'decoder.decoder_layers.3.attention.output.dense.weight', 'decoder.decoder_layers.6.layernorm_after.bias', 'decoder.decoder_layers.7.attention.attention.value.bias', 'decoder.decoder_layers.0.intermediate.dense.weight', 'decoder.decoder_layers.4.output.dense.weight', 'decoder.decoder_layers.3.attention.output.dense.bias', 'decoder.decoder_layers.7.attention.attention.query.bias', 'decoder.decoder_layers.4.attention.attention.query.bias', 'decoder.decoder_layers.4.attention.attention.key.bias', 'decoder.decoder_layers.1.layernorm_before.bias', 'decoder.decoder_layers.7.attention.attention.key.weight', 'decoder.decoder_layers.7.attention.attention.key.bias', 'decoder.decoder_layers.4.attention.output.dense.bias', 'decoder.decoder_layers.2.intermediate.dense.bias', 'decoder.decoder_layers.6.intermediate.dense.weight', 'decoder.decoder_layers.0.attention.attention.query.bias', 'decoder.decoder_layers.5.attention.attention.query.bias', 'decoder.decoder_layers.3.attention.attention.query.bias', 'decoder.decoder_layers.7.layernorm_before.bias', 'decoder.decoder_layers.0.attention.attention.query.weight', 'decoder.decoder_layers.3.layernorm_before.bias', 'decoder.decoder_layers.6.intermediate.dense.bias', 'decoder.decoder_layers.6.output.dense.weight', 'decoder.decoder_layers.5.attention.attention.value.weight', 'decoder.decoder_layers.2.attention.attention.value.weight', 'decoder.decoder_layers.1.output.dense.bias', 'decoder.decoder_layers.4.attention.output.dense.weight', 'decoder.decoder_layers.3.attention.attention.query.weight', 'decoder.decoder_layers.0.attention.attention.key.bias', 'decoder.decoder_layers.5.layernorm_after.weight', 'decoder.decoder_layers.0.attention.attention.key.weight', 'decoder.decoder_norm.weight', 'decoder.decoder_layers.1.intermediate.dense.bias', 'decoder.decoder_embed.bias', 'decoder.decoder_layers.1.attention.attention.key.bias', 'decoder.decoder_layers.2.attention.attention.key.weight', 'decoder.decoder_layers.1.layernorm_before.weight', 'decoder.decoder_layers.2.layernorm_before.bias', 'decoder.decoder_layers.1.attention.attention.query.bias', 'decoder.decoder_layers.7.layernorm_after.bias', 'decoder.decoder_layers.5.layernorm_before.bias', 'decoder.decoder_layers.6.attention.attention.query.weight', 'decoder.decoder_layers.5.attention.attention.value.bias', 'decoder.decoder_layers.5.attention.attention.key.weight', 'decoder.decoder_layers.7.layernorm_before.weight', 'decoder.decoder_layers.6.attention.attention.key.bias', 'decoder.decoder_layers.1.layernorm_after.bias', 'decoder.decoder_layers.7.attention.output.dense.weight', 'decoder.decoder_layers.5.attention.attention.query.weight', 'decoder.decoder_layers.5.intermediate.dense.weight', 'decoder.decoder_layers.4.layernorm_after.bias', 'decoder.decoder_layers.2.output.dense.bias', 'decoder.decoder_layers.4.attention.attention.key.weight', 'decoder.decoder_layers.7.attention.attention.query.weight', 'decoder.decoder_norm.bias', 'decoder.decoder_layers.2.attention.attention.query.bias', 'decoder.decoder_layers.3.layernorm_after.bias', 'decoder.decoder_layers.2.layernorm_before.weight', 'decoder.decoder_layers.3.attention.attention.value.weight', 'decoder.decoder_layers.1.attention.output.dense.weight', 'decoder.decoder_layers.0.output.dense.bias', 'decoder.decoder_layers.4.attention.attention.value.bias', 'decoder.decoder_layers.4.layernorm_before.bias', 'decoder.decoder_layers.0.layernorm_before.bias', 'decoder.decoder_layers.3.output.dense.bias', 'decoder.decoder_layers.5.attention.output.dense.weight', 'decoder.decoder_layers.7.attention.output.dense.bias', 'decoder.decoder_layers.6.attention.output.dense.bias', 'decoder.decoder_layers.7.output.dense.weight', 'decoder.decoder_layers.4.intermediate.dense.weight', 'decoder.decoder_layers.4.attention.attention.value.weight', 'decoder.decoder_layers.6.output.dense.bias', 'decoder.decoder_layers.5.output.dense.weight']
- This IS expected if you are initializing PIXELForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing PIXELForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[WARNING|modeling_utils.py:1704] 2023-11-23 17:59:23,092 >> Some weights of PIXELForSequenceClassification were not initialized from the model checkpoint at Team-PIXEL/pixel-base and are newly initialized: ['pooler.ln.bias', 'pooler.linear.weight', 'classifier.bias', 'classifier.weight', 'pooler.ln.weight', 'pooler.linear.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[INFO|file_utils.py:2215] 2023-11-23 17:59:23,256 >> https://huggingface.co/Team-PIXEL/pixel-base/resolve/main/text_renderer_config.json not found in cache or force_download set to True, downloading to /home2/s3919609/.cache/huggingface/transformers/tmpzc32ynyg
Downloading:   0%|          | 0.00/235 [00:00<?, ?B/s]Downloading: 100%|██████████| 235/235 [00:00<00:00, 733kB/s]
[INFO|file_utils.py:2219] 2023-11-23 17:59:23,417 >> storing https://huggingface.co/Team-PIXEL/pixel-base/resolve/main/text_renderer_config.json in cache at /home2/s3919609/.cache/huggingface/transformers/892d6a02d7c441000de399de59ed70d943a81f7b0f536523b4af1111677a8508.e332b34c9c05756dd4aa51d8fa33461dbd79604752296d185f03f8004db30700
[INFO|file_utils.py:2227] 2023-11-23 17:59:23,419 >> creating metadata file for /home2/s3919609/.cache/huggingface/transformers/892d6a02d7c441000de399de59ed70d943a81f7b0f536523b4af1111677a8508.e332b34c9c05756dd4aa51d8fa33461dbd79604752296d185f03f8004db30700
11/23/2023 17:59:23 - INFO - pixel.data.rendering.rendering_utils - loading text renderer configuration file https://huggingface.co/Team-PIXEL/pixel-base/resolve/main/text_renderer_config.json from cache at /home2/s3919609/.cache/huggingface/transformers/892d6a02d7c441000de399de59ed70d943a81f7b0f536523b4af1111677a8508.e332b34c9c05756dd4aa51d8fa33461dbd79604752296d185f03f8004db30700
[INFO|file_utils.py:2215] 2023-11-23 17:59:23,594 >> https://huggingface.co/Team-PIXEL/pixel-base/resolve/main/GoNotoCurrent.ttf not found in cache or force_download set to True, downloading to /home2/s3919609/.cache/huggingface/transformers/tmp1md3nse_
Downloading:   0%|          | 0.00/14.9M [00:00<?, ?B/s]Downloading:  26%|██▋       | 3.92M/14.9M [00:00<00:00, 41.1MB/s]Downloading:  78%|███████▊  | 11.6M/14.9M [00:00<00:00, 64.5MB/s]Downloading: 100%|██████████| 14.9M/14.9M [00:00<00:00, 68.1MB/s]
[INFO|file_utils.py:2219] 2023-11-23 17:59:23,915 >> storing https://huggingface.co/Team-PIXEL/pixel-base/resolve/main/GoNotoCurrent.ttf in cache at /home2/s3919609/.cache/huggingface/transformers/49e6dc219d1a1a1c9236acaf05a48b542002016a6dc877ee72baab085a84257b.3f28e7f4b38e1efe1b6da4a3732404c19d4c6a614ff32dce90a251e293d4ce58
[INFO|file_utils.py:2227] 2023-11-23 17:59:23,917 >> creating metadata file for /home2/s3919609/.cache/huggingface/transformers/49e6dc219d1a1a1c9236acaf05a48b542002016a6dc877ee72baab085a84257b.3f28e7f4b38e1efe1b6da4a3732404c19d4c6a614ff32dce90a251e293d4ce58
11/23/2023 17:59:23 - INFO - pixel.data.rendering.rendering_utils - loading font file https://huggingface.co/Team-PIXEL/pixel-base/resolve/main/GoNotoCurrent.ttf from cache at /home2/s3919609/.cache/huggingface/transformers/49e6dc219d1a1a1c9236acaf05a48b542002016a6dc877ee72baab085a84257b.3f28e7f4b38e1efe1b6da4a3732404c19d4c6a614ff32dce90a251e293d4ce58
11/23/2023 17:59:23 - INFO - pixel.data.rendering.pangocairo_renderer - Loading font from /home2/s3919609/.cache/huggingface/transformers/49e6dc219d1a1a1c9236acaf05a48b542002016a6dc877ee72baab085a84257b.3f28e7f4b38e1efe1b6da4a3732404c19d4c6a614ff32dce90a251e293d4ce58
11/23/2023 17:59:26 - INFO - pixel.data.rendering.rendering_utils - Text renderer PangoCairoTextRenderer {
  "background_color": "white",
  "dpi": 120,
  "font_color": "black",
  "font_file": "49e6dc219d1a1a1c9236acaf05a48b542002016a6dc877ee72baab085a84257b.3f28e7f4b38e1efe1b6da4a3732404c19d4c6a614ff32dce90a251e293d4ce58",
  "font_size": 8,
  "fonts_list": [
    "C059",
    "Cantarell",
    "D050000L",
    "DejaVu Sans",
    "DejaVu Sans Mono",
    "Droid Sans",
    "Droid Sans Arabic",
    "Droid Sans Armenian",
    "Droid Sans Devanagari",
    "Droid Sans Ethiopic",
    "Droid Sans Fallback",
    "Droid Sans Georgian",
    "Droid Sans Hebrew",
    "Droid Sans Japanese",
    "Droid Sans Tamil",
    "Droid Sans Thai",
    "Go Noto Current",
    "Inconsolata",
    "MathJax_AMS",
    "MathJax_Caligraphic",
    "MathJax_Fraktur",
    "MathJax_Main",
    "MathJax_Math",
    "MathJax_SansSerif",
    "MathJax_Script",
    "MathJax_Size1",
    "MathJax_Size2",
    "MathJax_Size3",
    "MathJax_Size4",
    "MathJax_Typewriter",
    "MathJax_Vector",
    "MathJax_Vector-Bold",
    "MathJax_WinChrome",
    "MathJax_WinIE6",
    "Monospace",
    "Nimbus Mono PS",
    "Nimbus Roman",
    "Nimbus Sans",
    "Nimbus Sans Narrow",
    "P052",
    "STIX MathJax Alphabets",
    "STIX MathJax Arrows",
    "STIX MathJax DoubleStruck",
    "STIX MathJax Fraktur",
    "STIX MathJax Latin",
    "STIX MathJax Main",
    "STIX MathJax Marks",
    "STIX MathJax Misc",
    "STIX MathJax Monospace",
    "STIX MathJax Normal",
    "STIX MathJax Operators",
    "STIX MathJax SansSerif",
    "STIX MathJax Script",
    "STIX MathJax Shapes",
    "STIX MathJax Size1",
    "STIX MathJax Size2",
    "STIX MathJax Size3",
    "STIX MathJax Size4",
    "STIX MathJax Size5",
    "STIX MathJax Symbols",
    "STIX MathJax Variants",
    "Sans",
    "Serif",
    "Source Code Pro",
    "System-ui",
    "URW Bookman",
    "URW Gothic",
    "Ubuntu",
    "Ubuntu Condensed",
    "Ubuntu Mono",
    "Z003"
  ],
  "max_seq_length": 529,
  "pad_size": 3,
  "pixels_per_patch": 16,
  "rgb": false,
  "text_renderer_type": "PangoCairoTextRenderer"
}

11/23/2023 17:59:26 - INFO - pixel.utils.modeling - Truncating position embeddings to 256
11/23/2023 17:59:27 - INFO - __main__ - Sample 14592 of the training set: {'sentence': 'a great movie ', 'label': 1, 'idx': 14592, 'pixel_values': tensor([[[1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         ...,
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.]],

        [[1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         ...,
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.]],

        [[1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         ...,
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.]]]), 'attention_mask': tensor([1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0.])}.
11/23/2023 17:59:27 - INFO - __main__ - Sample 3278 of the training set: {'sentence': 'entertaining , if somewhat standardized , action ', 'label': 1, 'idx': 3278, 'pixel_values': tensor([[[1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         ...,
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.]],

        [[1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         ...,
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.]],

        [[1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         ...,
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.]]]), 'attention_mask': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0.])}.
11/23/2023 17:59:27 - INFO - __main__ - Sample 36048 of the training set: {'sentence': 'even when there are lulls , the emotions seem authentic , ', 'label': 1, 'idx': 36048, 'pixel_values': tensor([[[1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         ...,
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.]],

        [[1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         ...,
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.]],

        [[1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         ...,
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.]]]), 'attention_mask': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0.])}.
11/23/2023 17:59:27 - INFO - __main__ - Sample 250 of the eval set: {'sentence': "one of the more intelligent children 's movies to hit theaters this year . ", 'label': 1, 'idx': 250, 'pixel_values': tensor([[[1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         ...,
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.]],

        [[1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         ...,
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.]],

        [[1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         ...,
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.]]]), 'attention_mask': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0.])}.
11/23/2023 17:59:27 - INFO - __main__ - Sample 228 of the eval set: {'sentence': 'it provides an honest look at a community striving to anchor itself in new grounds . ', 'label': 1, 'idx': 228, 'pixel_values': tensor([[[1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         ...,
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.]],

        [[1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         ...,
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.]],

        [[1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         ...,
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.]]]), 'attention_mask': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0.])}.
11/23/2023 17:59:27 - INFO - __main__ - Sample 142 of the eval set: {'sentence': "what better message than ` love thyself ' could young women of any size receive ? ", 'label': 1, 'idx': 142, 'pixel_values': tensor([[[1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         ...,
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.]],

        [[1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         ...,
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.]],

        [[1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         ...,
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.]]]), 'attention_mask': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0.])}.
/home2/s3919609/pixel-semantic/scripts/training/run_glue.py:604: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate
  metric = load_metric("glue", data_args.task_name)
https://raw.githubusercontent.com/huggingface/datasets/2.14.6/metrics/glue/glue.py not found in cache or force_download set to True, downloading to /home2/s3919609/.cache/huggingface/datasets/downloads/f624454343cfbf58c2f1b1fc66bad3ecfa066c451d4c8c5d9d782d2217fbe9a3.c2504e8be3fadd1d3b046519eb7f546ac2d3655ba91d4dbf7b75247b76e1abb1.py.incomplete
11/23/2023 17:59:28 - INFO - datasets.utils.file_utils - https://raw.githubusercontent.com/huggingface/datasets/2.14.6/metrics/glue/glue.py not found in cache or force_download set to True, downloading to /home2/s3919609/.cache/huggingface/datasets/downloads/f624454343cfbf58c2f1b1fc66bad3ecfa066c451d4c8c5d9d782d2217fbe9a3.c2504e8be3fadd1d3b046519eb7f546ac2d3655ba91d4dbf7b75247b76e1abb1.py.incomplete
Downloading builder script:   0%|          | 0.00/1.84k [00:00<?, ?B/s]Downloading builder script: 5.76kB [00:00, 15.5MB/s]                   
storing https://raw.githubusercontent.com/huggingface/datasets/2.14.6/metrics/glue/glue.py in cache at /home2/s3919609/.cache/huggingface/datasets/downloads/f624454343cfbf58c2f1b1fc66bad3ecfa066c451d4c8c5d9d782d2217fbe9a3.c2504e8be3fadd1d3b046519eb7f546ac2d3655ba91d4dbf7b75247b76e1abb1.py
11/23/2023 17:59:28 - INFO - datasets.utils.file_utils - storing https://raw.githubusercontent.com/huggingface/datasets/2.14.6/metrics/glue/glue.py in cache at /home2/s3919609/.cache/huggingface/datasets/downloads/f624454343cfbf58c2f1b1fc66bad3ecfa066c451d4c8c5d9d782d2217fbe9a3.c2504e8be3fadd1d3b046519eb7f546ac2d3655ba91d4dbf7b75247b76e1abb1.py
creating metadata file for /home2/s3919609/.cache/huggingface/datasets/downloads/f624454343cfbf58c2f1b1fc66bad3ecfa066c451d4c8c5d9d782d2217fbe9a3.c2504e8be3fadd1d3b046519eb7f546ac2d3655ba91d4dbf7b75247b76e1abb1.py
11/23/2023 17:59:28 - INFO - datasets.utils.file_utils - creating metadata file for /home2/s3919609/.cache/huggingface/datasets/downloads/f624454343cfbf58c2f1b1fc66bad3ecfa066c451d4c8c5d9d782d2217fbe9a3.c2504e8be3fadd1d3b046519eb7f546ac2d3655ba91d4dbf7b75247b76e1abb1.py
[INFO|trainer.py:430] 2023-11-23 17:59:28,386 >> max_steps is given, it will override any value given in num_train_epochs
/scratch/s3919609/conda/envs/pixel-sem-env/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
[INFO|trainer.py:1279] 2023-11-23 17:59:28,426 >> ***** Running training *****
[INFO|trainer.py:1280] 2023-11-23 17:59:28,426 >>   Num examples = 67349
[INFO|trainer.py:1281] 2023-11-23 17:59:28,426 >>   Num Epochs = 58
[INFO|trainer.py:1282] 2023-11-23 17:59:28,426 >>   Instantaneous batch size per device = 64
[INFO|trainer.py:1283] 2023-11-23 17:59:28,426 >>   Total train batch size (w. parallel, distributed & accumulation) = 256
[INFO|trainer.py:1284] 2023-11-23 17:59:28,426 >>   Gradient Accumulation steps = 4
[INFO|trainer.py:1285] 2023-11-23 17:59:28,426 >>   Total optimization steps = 15000
[INFO|integrations.py:575] 2023-11-23 17:59:28,449 >> Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
wandb: ERROR api_key not configured (no-tty). call wandb.login(key=[your_api_key])
Traceback (most recent call last):
  File "/home2/s3919609/pixel-semantic/scripts/training/run_glue.py", line 753, in <module>
    main()
  File "/home2/s3919609/pixel-semantic/scripts/training/run_glue.py", line 644, in main
    train_result = trainer.train(resume_from_checkpoint=checkpoint)
  File "/scratch/s3919609/conda/envs/pixel-sem-env/lib/python3.9/site-packages/transformers/trainer.py", line 1343, in train
    self.control = self.callback_handler.on_train_begin(args, self.state, self.control)
  File "/scratch/s3919609/conda/envs/pixel-sem-env/lib/python3.9/site-packages/transformers/trainer_callback.py", line 347, in on_train_begin
    return self.call_event("on_train_begin", args, state, control)
  File "/scratch/s3919609/conda/envs/pixel-sem-env/lib/python3.9/site-packages/transformers/trainer_callback.py", line 388, in call_event
    result = getattr(callback, event)(
  File "/scratch/s3919609/conda/envs/pixel-sem-env/lib/python3.9/site-packages/transformers/integrations.py", line 620, in on_train_begin
    self.setup(args, state, model, **kwargs)
  File "/scratch/s3919609/conda/envs/pixel-sem-env/lib/python3.9/site-packages/transformers/integrations.py", line 592, in setup
    self._wandb.init(
  File "/scratch/s3919609/conda/envs/pixel-sem-env/lib/python3.9/site-packages/wandb/sdk/wandb_init.py", line 1185, in init
    raise e
  File "/scratch/s3919609/conda/envs/pixel-sem-env/lib/python3.9/site-packages/wandb/sdk/wandb_init.py", line 1162, in init
    wi.setup(kwargs)
  File "/scratch/s3919609/conda/envs/pixel-sem-env/lib/python3.9/site-packages/wandb/sdk/wandb_init.py", line 306, in setup
    wandb_login._login(
  File "/scratch/s3919609/conda/envs/pixel-sem-env/lib/python3.9/site-packages/wandb/sdk/wandb_login.py", line 298, in _login
    wlogin.prompt_api_key()
  File "/scratch/s3919609/conda/envs/pixel-sem-env/lib/python3.9/site-packages/wandb/sdk/wandb_login.py", line 228, in prompt_api_key
    raise UsageError("api_key not configured (no-tty). call " + directive)
wandb.errors.UsageError: api_key not configured (no-tty). call wandb.login(key=[your_api_key])

###############################################################################
Hábrók Cluster
Job 6337008 for user s3919609
Finished at: Thu Nov 23 17:59:34 CET 2023

Job details:
============

Job ID              : 6337008
Name                : pixel_test_gpu
User                : s3919609
Partition           : gpushort
Nodes               : a100gpu3
Number of Nodes     : 1
Cores               : 40
Number of Tasks     : 1
State               : FAILED
Submit              : 2023-11-23T17:58:39
Start               : 2023-11-23T17:58:40
End                 : 2023-11-23T17:59:33
Reserved walltime   : 00:10:00
Used walltime       : 00:00:53
Used CPU time       : 00:01:00 (efficiency:  2.84%)
% User (Computation): 83.60%
% System (I/O)      : 16.40%
Mem reserved        : 32G
Max Mem (Node/step) : 295.62M (a100gpu3, per node)
Full Max Mem usage  : 295.62M
Total Disk Read     : 12.57M
Total Disk Write    : 364.32K

Acknowledgements:
=================

Please see this page for information about acknowledging Hábrók in your publications:

https://wiki.hpc.rug.nl/habrok/introduction/scientific_output

################################################################################
